{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use Trained Model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "49wcOWviXEDe",
        "colab_type": "code",
        "outputId": "24e73374-6a9a-49cc-feab-fe397d318432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_yaml\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8CCsn3QWXoWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/generator.h5\") as url:\n",
        "    generator_weights = url.read()\n",
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/generator.yaml\") as url:\n",
        "    generator_model = url.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSJISXMRa5gr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/flat_steps.json\") as url:\n",
        "    flat_steps = json.loads(url.read().decode())\n",
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/flat_ingredients.json\") as url:\n",
        "    flat_ingredients = json.loads(url.read().decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2KpS1c-occt-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decode The Generated Matrix\n",
        "\n",
        "Once we have a matrix generated, we need to decode it."
      ]
    },
    {
      "metadata": {
        "id": "btuEu_tqamGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deprocess(x):\n",
        "    x = (x / 2)\n",
        "    x += x + 0.5\n",
        "    x = x*8425231679608\n",
        "    x = np.clip(x, 0, 8425231679608)\n",
        "    x = np.uint64(x)\n",
        "    x = x.reshape(15, 20)\n",
        "    return x\n",
        "\n",
        "def decode_triplet(encoded_triplet):\n",
        "    encoded_triplet = int(encoded_triplet)\n",
        "    position = encoded_triplet % 100\n",
        "    encoded_triplet =  encoded_triplet // 100\n",
        "    step = encoded_triplet % 1000000\n",
        "    encoded_triplet = encoded_triplet // 1000000\n",
        "    ingredient = str(encoded_triplet)\n",
        "    return (ingredient, step, position)\n",
        "\n",
        "def decode_recipe_matrix(matrix):\n",
        "    rows = matrix.shape[0]\n",
        "    cols = matrix.shape[1]\n",
        "    recipe_encoded = {}\n",
        "    \n",
        "    for i in range(0, rows):\n",
        "        for j in range(0, cols):\n",
        "            if matrix[i][j] < 0.5 and matrix[i][j] > -0.5 :\n",
        "                continue\n",
        "            (ingredient, step, position) = decode_triplet(matrix[i][j])\n",
        "            if not position == 0:  \n",
        "                if ingredient not in recipe_encoded:\n",
        "                    recipe_encoded[ingredient] = []\n",
        "                recipe_encoded[ingredient].append([step, position])\n",
        "    return recipe_encoded\n",
        "\n",
        "def decode_recipe(encoded_recipe, flat_ingredients, flat_steps):\n",
        "    decoded_recipe = {}\n",
        "    decoded_recipe[\"ingredients\"] = set([])\n",
        "    decoded_recipe[\"steps\"] = set([])\n",
        "    for ingredient_id in encoded_recipe:\n",
        "        ingredient_id = str(int(ingredient_id) % 84253)\n",
        "        decoded_recipe[\"ingredients\"].add(flat_ingredients[int(ingredient_id)])\n",
        "        for (step_id, position) in encoded_recipe[ingredient_id]:\n",
        "            step_id = step_id % 452362\n",
        "            try:\n",
        "                decoded_recipe[\"steps\"].add((flat_steps[step_id], position))\n",
        "            except IndexError:\n",
        "                print(step_id)\n",
        "    \n",
        "    decoded_recipe[\"ingredients\"] = list(decoded_recipe[\"ingredients\"])\n",
        "    decoded_recipe[\"steps\"] = list(decoded_recipe[\"steps\"])\n",
        "    decoded_recipe['steps'] =  sorted(decoded_recipe['steps'], key=lambda tup: tup[1])\n",
        "    decoded_recipe['steps'] = [ seq[0] for seq in decoded_recipe['steps'] ]\n",
        "\n",
        "    return decoded_recipe\n",
        "\n",
        "def full_decode_to_original(matrix_recipe, flat_ingredients, flat_steps):\n",
        "    matrix_recipe = deprocess(matrix_recipe)\n",
        "    decoded_matrix_json = decode_recipe_matrix(matrix_recipe)\n",
        "    original_recipe = decode_recipe(decoded_matrix_json, flat_ingredients, flat_steps)\n",
        "    return original_recipe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNplOFegcqXP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Model & Weights\n",
        "\n",
        "We load the previously trained model and weights"
      ]
    },
    {
      "metadata": {
        "id": "POJPYPbyYM4O",
        "colab_type": "code",
        "outputId": "32ac1483-811f-499c-f079-bbea933d1831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "generator = model_from_yaml(generator_model)\n",
        "weights_path = get_file('generator.h5','https://people.ucsc.edu/~gcollelu/generator.h5')\n",
        "generator.load_weights(weights_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://people.ucsc.edu/~gcollelu/generator.h5\n",
            "221184/219680 [==============================] - 1s 3us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SkqAviZ2Z8h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VB2DpunDaPCy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_latent_samples(sample_size):\n",
        "    #return np.random.uniform(-1, 1, size=(n_samples, sample_size))\n",
        "    return np.random.normal(loc=0, scale=1, size=(1, sample_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjiFqO_MczSN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate New Recipe\n",
        "\n",
        "Now, we generate a new recipe"
      ]
    },
    {
      "metadata": {
        "id": "h5j0amm5bHjS",
        "colab_type": "code",
        "outputId": "2a14d314-6f91-48bb-e60d-82eb0226a800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "latent_samples = make_latent_samples(100)\n",
        "generated_recipe = generator.predict(latent_samples)\n",
        "original_recipe = full_decode_to_original(generated_recipe, flat_ingredients, flat_steps)\n",
        "print(json.dumps(original_recipe, indent=2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ingredients\": [\n",
            "    \"head green cabbage, chopped\",\n",
            "    \"ruby port\",\n",
            "    \"slices bacon, cooked crisp and crumbled, divided\",\n",
            "    \"seedless orange, peeled, chopped\",\n",
            "    \"blue cheese crumbles, divided\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Slice chicken breasts on the diagonal into 1/2 inch thick slices\",\n",
            "    \"Divide dough into 4 equal portions\",\n",
            "    \"Spoon onto the toasted baguette rounds\",\n",
            "    \"Process until mixture is bright green and smooth\",\n",
            "    \"Bake the kale for 10 minutes, watching carefully to prevent burning, until the kale is crisp and the cheese is browned\"\n",
            "  ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}