{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Keras_Steps_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XqYm_r58zNxL",
        "colab_type": "code",
        "outputId": "14d4c5d3-1486-4a71-aa5e-d73aae4d2175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import keras\n",
        "from gensim.models import word2vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.models import Model,Sequential\n",
        "from keras.datasets import mnist\n",
        "from tqdm import tqdm\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Input, Dense, Activation, LeakyReLU, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import adam\n",
        "import keras.backend as K\n",
        "import math\n",
        "from scipy import sparse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uNMfsnPvM1nP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download & Prepare Dataset\n",
        "\n",
        "We downloaded all the different components needed for the cleaned dataset we previously generated."
      ]
    },
    {
      "metadata": {
        "id": "60YcvTkxgqTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request, json \n",
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/encoded_recipes.json\") as url:\n",
        "    recipes_encoded = json.loads(url.read().decode())\n",
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/recipes.json\") as url:\n",
        "    recipes = json.loads(url.read().decode())\n",
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/flat_steps.json\") as url:\n",
        "    flat_steps = json.loads(url.read().decode())\n",
        "with urllib.request.urlopen(\"https://people.ucsc.edu/~gcollelu/flat_ingredients.json\") as url:\n",
        "    flat_ingredients = json.loads(url.read().decode())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qRzZ8IRRbpup",
        "colab_type": "code",
        "outputId": "27c21909-2371-4918-94ef-81dc43c49669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13481
        }
      },
      "cell_type": "code",
      "source": [
        "print(json.dumps(recipes_encoded[6425], indent=2))\n",
        "print(json.dumps(recipes[6425], indent=2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"67132\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      176282,\n",
            "      1\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      283623,\n",
            "      9\n",
            "    ],\n",
            "    [\n",
            "      72872,\n",
            "      10\n",
            "    ]\n",
            "  ],\n",
            "  \"75794\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      176282,\n",
            "      1\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      283623,\n",
            "      9\n",
            "    ],\n",
            "    [\n",
            "      72872,\n",
            "      10\n",
            "    ]\n",
            "  ],\n",
            "  \"34874\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      176282,\n",
            "      1\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      72872,\n",
            "      10\n",
            "    ]\n",
            "  ],\n",
            "  \"44974\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      176282,\n",
            "      1\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      72872,\n",
            "      10\n",
            "    ]\n",
            "  ],\n",
            "  \"24356\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ]\n",
            "  ],\n",
            "  \"66079\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      283623,\n",
            "      9\n",
            "    ]\n",
            "  ],\n",
            "  \"74651\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      283623,\n",
            "      9\n",
            "    ]\n",
            "  ],\n",
            "  \"41737\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      176282,\n",
            "      1\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      395500,\n",
            "      2\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      235512,\n",
            "      4\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      120774,\n",
            "      6\n",
            "    ],\n",
            "    [\n",
            "      120774,\n",
            "      6\n",
            "    ],\n",
            "    [\n",
            "      120774,\n",
            "      6\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      72872,\n",
            "      10\n",
            "    ]\n",
            "  ],\n",
            "  \"67572\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ]\n",
            "  ],\n",
            "  \"72249\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ]\n",
            "  ],\n",
            "  \"35300\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ]\n",
            "  ],\n",
            "  \"62053\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ]\n",
            "  ],\n",
            "  \"59617\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ],\n",
            "    [\n",
            "      54809,\n",
            "      8\n",
            "    ]\n",
            "  ],\n",
            "  \"233\": [\n",
            "    [\n",
            "      362429,\n",
            "      0\n",
            "    ],\n",
            "    [\n",
            "      360632,\n",
            "      3\n",
            "    ],\n",
            "    [\n",
            "      418616,\n",
            "      5\n",
            "    ],\n",
            "    [\n",
            "      239999,\n",
            "      7\n",
            "    ]\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"id\": 7654,\n",
            "  \"title\": \"Greek Pasta Salad with Roasted Vegetables and Feta\",\n",
            "  \"ingredients\": [\n",
            "    \"red bell pepper, cut into 1/2 inch pieces\",\n",
            "    \"yellow bell pepper, chopped\",\n",
            "    \"medium eggplant, cubed\",\n",
            "    \"small yellow squash, cut in 1/4 inch slices\",\n",
            "    \"extra virgin olive oil\",\n",
            "    \"salt\",\n",
            "    \"ground black pepper\",\n",
            "    \"sun-dried tomatoes, soaked in 1/2 cup boiling water\",\n",
            "    \"torn arugula leaves\",\n",
            "    \"chopped fresh basil\",\n",
            "    \"balsamic vinegar\",\n",
            "    \"minced garlic\",\n",
            "    \"crumbled feta cheese\",\n",
            "    \"farfalle pasta\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Preheat oven to 450 degrees F (230 degrees C)\",\n",
            "    \"Line a cookie sheet with foil, and spray with non-stick cooking spray\",\n",
            "    \"In a medium bowl toss the red bell pepper, yellow bell pepper, eggplant, and squash with 2 tablespoons of the olive oil, salt, and pepper\",\n",
            "    \"Arrange on the prepared cookie sheet\",\n",
            "    \"Bake vegetables 25 minutes in the preheated oven, tossing occasionally, until lightly browned\",\n",
            "    \"In a large pot of salted boiling water, cook pasta 10 to 12 minutes, until al dente, and drain\",\n",
            "    \"Drain the softened sun-dried tomatoes and reserve the water\",\n",
            "    \"In a large bowl, toss together the roasted vegetables, cooked pasta, sun-drained tomatoes, arugula, and basil\",\n",
            "    \"Mix in remaining olive oil, reserved water from tomatoes, balsamic vinegar, garlic, and feta cheese; toss to coat\",\n",
            "    \"Season with salt and pepper to taste\",\n",
            "    \"Serve immediately, or refrigerate until chilled\"\n",
            "  ],\n",
            "  \"rating\": 4.59\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3Il15eC4DGMX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Converting previously encoded recipes to 15x20 matrix\n",
        "\n",
        "Now we need to represent the matrix in a more concise way. We do so, by translating the 2D 452362x84253 sparse matrix into a 15x20 dense matrix in which each entry represents an encoding of `(ingredient, step, step_position)`. This way, we will be able to use the matrix for our model.\n"
      ]
    },
    {
      "metadata": {
        "id": "_GxU8BKEEIEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_triplet(ingredient, step, position):\n",
        "    # Padding indices\n",
        "    position = \"%0*d\" % (2, position)\n",
        "    step = \"%0*d\" % (6, step)\n",
        "    ingredient = \"%0*d\" % (5, int(ingredient))\n",
        "    encoded = ingredient + step + position\n",
        "    return int(encoded)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OrWPUAVSNNIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_triplet(encoded_triplet):\n",
        "    encoded_triplet = int(encoded_triplet)\n",
        "    position = encoded_triplet % 100\n",
        "    encoded_triplet =  encoded_triplet // 100\n",
        "    step = encoded_triplet % 1000000\n",
        "    encoded_triplet = encoded_triplet // 1000000\n",
        "    ingredient = str(encoded_triplet)\n",
        "    return (ingredient, step, position)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGI53eOTCsNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_recipe_matrix(encoded_recipe):\n",
        "    recipe_en = np.zeros(shape=(15,20), dtype=np.uint64)\n",
        "    ingredient_count = 0\n",
        "    steps_seen = {}\n",
        "    for ingredient_id in encoded_recipe:\n",
        "        step_count = 0\n",
        "        for (step_id, position) in encoded_recipe[ingredient_id]:\n",
        "            encoded_triplet = encode_triplet(ingredient_id, step_id, position)\n",
        "            recipe_en[ingredient_count][step_count] = encoded_triplet\n",
        "            if step_id not in steps_seen:\n",
        "                steps_seen[step_id] = True\n",
        "                step_count += 1\n",
        "        ingredient_count += 1\n",
        "    return recipe_en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OQJCWkUONI8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_recipe_matrix(matrix):\n",
        "    rows = matrix.shape[0]\n",
        "    cols = matrix.shape[1]\n",
        "    recipe_encoded = {}\n",
        "    \n",
        "    for i in range(0, rows):\n",
        "        for j in range(0, cols):\n",
        "            if matrix[i][j] < 0.5 and matrix[i][j] > -0.5 :\n",
        "                continue\n",
        "            (ingredient, step, position) = decode_triplet(matrix[i][j])\n",
        "            if not position == 0:  \n",
        "                if ingredient not in recipe_encoded:\n",
        "                    recipe_encoded[ingredient] = []\n",
        "                recipe_encoded[ingredient].append([step, position])\n",
        "    return recipe_encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x94zKCpOQlgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_recipe(encoded_recipe, flat_ingredients, flat_steps):\n",
        "    decoded_recipe = {}\n",
        "    decoded_recipe[\"ingredients\"] = set([])\n",
        "    decoded_recipe[\"steps\"] = set([])\n",
        "    for ingredient_id in encoded_recipe:\n",
        "        ingredient_id = str(int(ingredient_id) % 84253)\n",
        "        decoded_recipe[\"ingredients\"].add(flat_ingredients[int(ingredient_id)])\n",
        "        for (step_id, position) in encoded_recipe[ingredient_id]:\n",
        "            step_id = step_id % 452362\n",
        "            try:\n",
        "                decoded_recipe[\"steps\"].add((flat_steps[step_id], position))\n",
        "            except IndexError:\n",
        "                print(step_id)\n",
        "    \n",
        "    decoded_recipe[\"ingredients\"] = list(decoded_recipe[\"ingredients\"])\n",
        "    decoded_recipe[\"steps\"] = list(decoded_recipe[\"steps\"])\n",
        "    decoded_recipe['steps'] =  sorted(decoded_recipe['steps'], key=lambda tup: tup[1])\n",
        "    decoded_recipe['steps'] = [ seq[0] for seq in decoded_recipe['steps'] ]\n",
        "\n",
        "    return decoded_recipe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9zIvUpSam3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def full_decode_to_original(matrix_recipe, flat_ingredients, flat_steps):\n",
        "    decoded_matrix_json = decode_recipe_matrix(matrix_recipe)\n",
        "    original_recipe = decode_recipe(decoded_matrix_json, flat_ingredients, flat_steps)\n",
        "    return original_recipe\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K9KOGGrQFgmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "print(json.dumps(recipes[200], indent=2))\n",
        "# print(recipes_encoded[200])\n",
        "encoded_matrix = encode_recipe_matrix(recipes_encoded[200])\n",
        "decoded_matrix_json = decode_recipe_matrix(encoded_matrix)\n",
        "# print(decoded_matrix_json)\n",
        "decoded_recipe = decode_recipe(decoded_matrix_json, flat_ingredients, flat_steps)\n",
        "print(json.dumps(decode_recipe, indent=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYB47Le6TTL0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recipes2small_matrices(encoded_recipes):\n",
        "    matrices = []\n",
        "    for i in tqdm(range(len(encoded_recipes))):\n",
        "        recipe = encoded_recipes[i]\n",
        "        matrices.append(encode_recipe_matrix(recipe))\n",
        "    matrices = np.stack(matrices)\n",
        "    return matrices  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Cx2V4MiTmzV",
        "colab_type": "code",
        "outputId": "515b3d8c-de3d-44c8-ecbb-761c3c19f7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "matrices = recipes2small_matrices(recipes_encoded)\n",
        "print(matrices.shape)\n",
        "# matrices.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 76549/76549 [00:08<00:00, 8736.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(76549, 15, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "voP5fsmLZmNs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(recipes_matrices):\n",
        "    train_length = math.floor(len(recipes_matrices)/2)\n",
        "    train_data = np.array([np.array(recipe) for recipe in recipes_matrices[:train_length]])\n",
        "    test_data = np.array([np.array(recipe) for recipe in recipes_matrices[train_length:]])\n",
        "    return (train_data, test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfT9_TJPZt2A",
        "colab_type": "code",
        "outputId": "75114d01-384c-4424-94d7-4c6d8a666bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test = load_data(matrices)\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38274, 15, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "d0Db3Je5MgDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "We need to flatten the recipe matrix as the fully connected input layer expects that. Also, as the generator uses the tanh activation in the output layer, we scale all the data images to have values between -1 and 1."
      ]
    },
    {
      "metadata": {
        "id": "6WYb5uw2MQCQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(x):    \n",
        "    x = x.reshape(-1, 300) # 300 = 15*20\n",
        "    x = np.float64(x)\n",
        "    x = (x / 8425231679608 -0.5) * 2\n",
        "    x = np.clip(x, -1, 1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gARBIEYBN1hF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_real = preprocess(X_train)\n",
        "X_test_real  = preprocess(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xQ6U16XNLfp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deprocessing\n",
        "We also need a function to reverse the preprocessing so that we can display generated recipes."
      ]
    },
    {
      "metadata": {
        "id": "HPhSRMGkNReo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deprocess(x):\n",
        "    x = (x / 2)\n",
        "    x += x + 0.5\n",
        "    x = x*8425231679608\n",
        "    x = np.clip(x, 0, 8425231679608)\n",
        "    x = np.uint64(x)\n",
        "    x = x.reshape(15, 20)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ydCxrDlEaIBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(\"Preprocessed\")\n",
        "    print(X_train_real[i])\n",
        "    recipe = deprocess(X_train_real[i])\n",
        "    original_recipe = full_decode_to_original(recipe, flat_ingredients, flat_steps)\n",
        "    print(json.dumps(original_recipe, indent=2))\n",
        "    break\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rz9VVf-_it-a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GAN Implementation\n",
        "\n",
        "Now we need to have the model for the generator and the discriminator."
      ]
    },
    {
      "metadata": {
        "id": "2Kh786sXjhQ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generator\n",
        "\n",
        "We need to implement a generator model"
      ]
    },
    {
      "metadata": {
        "id": "5SHwmdgsjlQQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_latent_samples(n_samples, sample_size):\n",
        "    #return np.random.uniform(-1, 1, size=(n_samples, sample_size))\n",
        "    return np.random.normal(loc=0, scale=1, size=(n_samples, sample_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5DdRwM4jzYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The sample size is a hyperparameter. Below, we use a vector of 100 randomly generated number as a sample."
      ]
    },
    {
      "metadata": {
        "id": "D9YxmIp_jvM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "make_latent_samples(1, 300) # generates one sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpYY1PB1j8Uu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generator is a simple fully connected neural network with one hidden layer with the leaky ReLU activation. It takes one latent sample (100 values) and produces 300 (=15x20) data points which represent a digit image.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dNTNZuA-lWpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GAN\n",
        "\n",
        "We connect the generator and the discriminator to produce a GAN.\n",
        "\n",
        "It takes the latent sample, and the generator inside GAN produces a digit image which the discriminator inside GAN classifies as real or fake.\n",
        "\n",
        "If the generated digit image is so realistic, the discriminator in the GAN classifies it as real, which is what we want to achieve.\n",
        "\n",
        "We set the discriminator inside the GAN not-trainable, so it is merely evaluating the quality of the generated image. The label is always 1 (real) so that if the generator fails to produce a realistic digit image, its cost becomes high, and when the back-propagation occurs in GAN, the weights in the generator network gets updated."
      ]
    },
    {
      "metadata": {
        "id": "Vois3KVmlp6i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As you can see, the GAN internally uses the same generator and the discriminator models. The GAN maintains the same shared weights with the generator and the disriminator. Therefore, training the GAN also trains the generator. However, we do not want the discriminator to be affected while training the GAN."
      ]
    },
    {
      "metadata": {
        "id": "RW-0LIpUlql7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_trainable(model, trainable):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "952Hp-gol7Td",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_simple_GAN(sample_size, \n",
        "                    g_hidden_size, \n",
        "                    d_hidden_size, \n",
        "                    leaky_alpha, \n",
        "                    g_learning_rate,\n",
        "                    d_learning_rate):\n",
        "    K.clear_session()\n",
        "    \n",
        "    generator = Sequential([\n",
        "        Dense(g_hidden_size, input_shape=(sample_size,)),\n",
        "        LeakyReLU(alpha=leaky_alpha),\n",
        "        Dense(300),        \n",
        "        Activation('tanh')\n",
        "    ], name='generator')    \n",
        "\n",
        "    discriminator = Sequential([\n",
        "        Dense(d_hidden_size, input_shape=(300,)),\n",
        "        LeakyReLU(alpha=leaky_alpha),\n",
        "        Dense(1),\n",
        "        Activation('sigmoid')\n",
        "    ], name='discriminator')    \n",
        "    \n",
        "    gan = Sequential([\n",
        "        generator,\n",
        "        discriminator\n",
        "    ])\n",
        "    \n",
        "    discriminator.compile(optimizer=Adam(lr=d_learning_rate), loss='binary_crossentropy')\n",
        "    gan.compile(optimizer=Adam(lr=g_learning_rate), loss='binary_crossentropy')\n",
        "    \n",
        "    return gan, generator, discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Um9nLxRll8xJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training GAN\n",
        "\n",
        "### Labels\n",
        "\n",
        "The labels are 1 (real) or 0 (fake) in 2D shape."
      ]
    },
    {
      "metadata": {
        "id": "7FjLEZE3mNB-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_labels(size):\n",
        "    return np.ones([size, 1]), np.zeros([size, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWE9-m5lmXI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Label Smoothing\n",
        "One last point before we start training is the label smoothing which makes the discriminator generalize better [4].\n",
        "\n",
        "For the real digit images, the labels are all 1s. However, when we train the discriminator, we use a value slightly smaller than 1 with the real digit images. Otherwise, the discriminator might overfit to the training data and rejects anything else that is slightly different from the training images."
      ]
    },
    {
      "metadata": {
        "id": "8x4Je98kmf7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training Loop\n",
        "We repeat the following to make both the discriminator and the generator better and better:\n",
        "\n",
        "\n",
        "\n",
        "*   Prepare a batch of real recipes\n",
        "*   Prepare a batch of fake recipes generated by the generator using latent samples\n",
        "*   Make the discriminator trainable\n",
        "*   Train the discriminator to classify the real and fake recipes\n",
        "*   Make the discriminator non-trainable\n",
        "*   Train the generator via the GAN\n",
        "\n",
        "When training the generator via the GAN, the expect labels are all 1s (real). Initially, the generator produces not very realistic recipes so the discriminator classifies them as 0s (fake), which causes the back-propagation to adjust the weights inside the generator. The discriminator is not affected as we set it non-trainable in this step."
      ]
    },
    {
      "metadata": {
        "id": "nCpF11Rsmczy",
        "colab_type": "code",
        "outputId": "753ac643-1cd4-4f37-b620-7798625e3161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17071
        }
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "sample_size     = 100     # latent sample size (i.e., 100 random numbers)\n",
        "g_hidden_size   = 128\n",
        "d_hidden_size   = 128\n",
        "leaky_alpha     = 0.01\n",
        "g_learning_rate = 0.0001  # learning rate for the generator\n",
        "d_learning_rate = 0.001   # learning rate for the discriminator\n",
        "epochs          = 1000\n",
        "batch_size      = 64      # train batch size\n",
        "eval_size       = 16      # evaluate size\n",
        "smooth          = 0.1\n",
        "\n",
        "# labels for the batch size and the test size\n",
        "y_train_real, y_train_fake = make_labels(batch_size)\n",
        "y_eval_real,  y_eval_fake  = make_labels(eval_size)\n",
        "\n",
        "# print(y_train_real)\n",
        "# print(\"fake\")\n",
        "# print(y_train_fake)\n",
        "\n",
        "# create a GAN, a generator and a discriminator\n",
        "gan, generator, discriminator = make_simple_GAN(\n",
        "    sample_size, \n",
        "    g_hidden_size, \n",
        "    d_hidden_size, \n",
        "    leaky_alpha, \n",
        "    g_learning_rate,\n",
        "    d_learning_rate)\n",
        "\n",
        "losses = []\n",
        "for e in range(epochs):\n",
        "    for i in range(len(X_train_real)//batch_size):\n",
        "        # real MNIST digit images\n",
        "        X_batch_real = X_train_real[i*batch_size:(i+1)*batch_size]\n",
        "        \n",
        "        # latent samples and the generated digit images\n",
        "        latent_samples = make_latent_samples(batch_size, sample_size)\n",
        "        X_batch_fake = generator.predict_on_batch(latent_samples)\n",
        "        \n",
        "        # train the discriminator to detect real and fake images\n",
        "        make_trainable(discriminator, True)\n",
        "        discriminator.train_on_batch(X_batch_real, y_train_real * (1 - smooth))\n",
        "        discriminator.train_on_batch(X_batch_fake, y_train_fake)\n",
        "\n",
        "        # train the generator via GAN\n",
        "        make_trainable(discriminator, False)\n",
        "        gan.train_on_batch(latent_samples, y_train_real)\n",
        "    \n",
        "    # evaluate\n",
        "    X_eval_real = X_test_real[np.random.choice(len(X_test_real), eval_size, replace=False)]\n",
        "    \n",
        "    latent_samples = make_latent_samples(eval_size, sample_size)\n",
        "    X_eval_fake = generator.predict_on_batch(latent_samples)\n",
        "\n",
        "    d_loss  = discriminator.test_on_batch(X_eval_real, y_eval_real)\n",
        "    d_loss += discriminator.test_on_batch(X_eval_fake, y_eval_fake)\n",
        "    g_loss  = gan.test_on_batch(latent_samples, y_eval_real) # we want the fake to be realistic!\n",
        "    \n",
        "    losses.append((d_loss, g_loss))\n",
        "    \n",
        "    print(\"Epoch: {:>3}/{} Discriminator Loss: {:>6.4f} Generator Loss: {:>6.4f}\".format(\n",
        "        e+1, epochs, d_loss, g_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:   1/1000 Discriminator Loss: 0.1722 Generator Loss: 3.3118\n",
            "Epoch:   2/1000 Discriminator Loss: 0.3316 Generator Loss: 2.3903\n",
            "Epoch:   3/1000 Discriminator Loss: 0.8853 Generator Loss: 1.2627\n",
            "Epoch:   4/1000 Discriminator Loss: 0.9200 Generator Loss: 1.2654\n",
            "Epoch:   5/1000 Discriminator Loss: 1.0772 Generator Loss: 0.9486\n",
            "Epoch:   6/1000 Discriminator Loss: 1.2974 Generator Loss: 0.7523\n",
            "Epoch:   7/1000 Discriminator Loss: 1.0810 Generator Loss: 0.9664\n",
            "Epoch:   8/1000 Discriminator Loss: 1.4419 Generator Loss: 1.1142\n",
            "Epoch:   9/1000 Discriminator Loss: 1.5025 Generator Loss: 0.8382\n",
            "Epoch:  10/1000 Discriminator Loss: 1.3668 Generator Loss: 0.7701\n",
            "Epoch:  11/1000 Discriminator Loss: 1.2967 Generator Loss: 0.9437\n",
            "Epoch:  12/1000 Discriminator Loss: 1.2499 Generator Loss: 0.9266\n",
            "Epoch:  13/1000 Discriminator Loss: 1.4933 Generator Loss: 0.9318\n",
            "Epoch:  14/1000 Discriminator Loss: 1.1582 Generator Loss: 0.9252\n",
            "Epoch:  15/1000 Discriminator Loss: 1.2730 Generator Loss: 1.1686\n",
            "Epoch:  16/1000 Discriminator Loss: 1.3919 Generator Loss: 1.0061\n",
            "Epoch:  17/1000 Discriminator Loss: 1.0372 Generator Loss: 0.8192\n",
            "Epoch:  18/1000 Discriminator Loss: 0.6081 Generator Loss: 1.5812\n",
            "Epoch:  19/1000 Discriminator Loss: 0.5141 Generator Loss: 2.2521\n",
            "Epoch:  20/1000 Discriminator Loss: 0.3807 Generator Loss: 2.0006\n",
            "Epoch:  21/1000 Discriminator Loss: 0.4242 Generator Loss: 2.1067\n",
            "Epoch:  22/1000 Discriminator Loss: 0.6452 Generator Loss: 1.6827\n",
            "Epoch:  23/1000 Discriminator Loss: 1.0151 Generator Loss: 0.8394\n",
            "Epoch:  24/1000 Discriminator Loss: 1.1609 Generator Loss: 1.1780\n",
            "Epoch:  25/1000 Discriminator Loss: 1.3341 Generator Loss: 0.8772\n",
            "Epoch:  26/1000 Discriminator Loss: 1.2668 Generator Loss: 0.9448\n",
            "Epoch:  27/1000 Discriminator Loss: 1.2806 Generator Loss: 0.7633\n",
            "Epoch:  28/1000 Discriminator Loss: 1.2269 Generator Loss: 0.8962\n",
            "Epoch:  29/1000 Discriminator Loss: 1.0024 Generator Loss: 0.9926\n",
            "Epoch:  30/1000 Discriminator Loss: 0.8760 Generator Loss: 1.3446\n",
            "Epoch:  31/1000 Discriminator Loss: 1.1021 Generator Loss: 1.1694\n",
            "Epoch:  32/1000 Discriminator Loss: 1.5130 Generator Loss: 1.0188\n",
            "Epoch:  33/1000 Discriminator Loss: 0.6214 Generator Loss: 1.5803\n",
            "Epoch:  34/1000 Discriminator Loss: 0.8734 Generator Loss: 1.3472\n",
            "Epoch:  35/1000 Discriminator Loss: 0.6309 Generator Loss: 1.4083\n",
            "Epoch:  36/1000 Discriminator Loss: 1.3606 Generator Loss: 1.0828\n",
            "Epoch:  37/1000 Discriminator Loss: 0.9111 Generator Loss: 1.2673\n",
            "Epoch:  38/1000 Discriminator Loss: 0.7021 Generator Loss: 1.7175\n",
            "Epoch:  39/1000 Discriminator Loss: 1.1723 Generator Loss: 1.3958\n",
            "Epoch:  40/1000 Discriminator Loss: 0.9024 Generator Loss: 1.6364\n",
            "Epoch:  41/1000 Discriminator Loss: 1.2800 Generator Loss: 1.2553\n",
            "Epoch:  42/1000 Discriminator Loss: 1.4559 Generator Loss: 0.9951\n",
            "Epoch:  43/1000 Discriminator Loss: 1.0420 Generator Loss: 1.1573\n",
            "Epoch:  44/1000 Discriminator Loss: 1.3636 Generator Loss: 1.1871\n",
            "Epoch:  45/1000 Discriminator Loss: 1.3409 Generator Loss: 1.1465\n",
            "Epoch:  46/1000 Discriminator Loss: 0.8149 Generator Loss: 1.6051\n",
            "Epoch:  47/1000 Discriminator Loss: 0.7212 Generator Loss: 1.5328\n",
            "Epoch:  48/1000 Discriminator Loss: 1.0776 Generator Loss: 1.0604\n",
            "Epoch:  49/1000 Discriminator Loss: 0.9234 Generator Loss: 1.4016\n",
            "Epoch:  50/1000 Discriminator Loss: 0.9778 Generator Loss: 1.1253\n",
            "Epoch:  51/1000 Discriminator Loss: 0.9605 Generator Loss: 1.3566\n",
            "Epoch:  52/1000 Discriminator Loss: 0.5897 Generator Loss: 1.7335\n",
            "Epoch:  53/1000 Discriminator Loss: 1.1898 Generator Loss: 0.9249\n",
            "Epoch:  54/1000 Discriminator Loss: 1.2572 Generator Loss: 0.9143\n",
            "Epoch:  55/1000 Discriminator Loss: 1.5750 Generator Loss: 0.7721\n",
            "Epoch:  56/1000 Discriminator Loss: 0.9799 Generator Loss: 1.4291\n",
            "Epoch:  57/1000 Discriminator Loss: 1.3461 Generator Loss: 1.3306\n",
            "Epoch:  58/1000 Discriminator Loss: 1.0441 Generator Loss: 1.1225\n",
            "Epoch:  59/1000 Discriminator Loss: 0.8168 Generator Loss: 1.6854\n",
            "Epoch:  60/1000 Discriminator Loss: 0.9106 Generator Loss: 1.5281\n",
            "Epoch:  61/1000 Discriminator Loss: 0.8313 Generator Loss: 1.2900\n",
            "Epoch:  62/1000 Discriminator Loss: 1.3353 Generator Loss: 1.1382\n",
            "Epoch:  63/1000 Discriminator Loss: 0.8192 Generator Loss: 1.5757\n",
            "Epoch:  64/1000 Discriminator Loss: 1.4643 Generator Loss: 0.9324\n",
            "Epoch:  65/1000 Discriminator Loss: 1.2862 Generator Loss: 1.2182\n",
            "Epoch:  66/1000 Discriminator Loss: 1.2094 Generator Loss: 1.1260\n",
            "Epoch:  67/1000 Discriminator Loss: 1.2132 Generator Loss: 1.1918\n",
            "Epoch:  68/1000 Discriminator Loss: 0.8108 Generator Loss: 1.8056\n",
            "Epoch:  69/1000 Discriminator Loss: 0.7525 Generator Loss: 1.5690\n",
            "Epoch:  70/1000 Discriminator Loss: 1.6108 Generator Loss: 1.0287\n",
            "Epoch:  71/1000 Discriminator Loss: 1.1204 Generator Loss: 1.4624\n",
            "Epoch:  72/1000 Discriminator Loss: 1.1245 Generator Loss: 1.3524\n",
            "Epoch:  73/1000 Discriminator Loss: 1.2819 Generator Loss: 1.3428\n",
            "Epoch:  74/1000 Discriminator Loss: 1.3229 Generator Loss: 1.4887\n",
            "Epoch:  75/1000 Discriminator Loss: 0.7826 Generator Loss: 1.2641\n",
            "Epoch:  76/1000 Discriminator Loss: 1.2922 Generator Loss: 1.5305\n",
            "Epoch:  77/1000 Discriminator Loss: 1.1354 Generator Loss: 1.6255\n",
            "Epoch:  78/1000 Discriminator Loss: 0.8881 Generator Loss: 1.0588\n",
            "Epoch:  79/1000 Discriminator Loss: 1.0661 Generator Loss: 1.5385\n",
            "Epoch:  80/1000 Discriminator Loss: 1.3041 Generator Loss: 1.4292\n",
            "Epoch:  81/1000 Discriminator Loss: 1.1327 Generator Loss: 1.2500\n",
            "Epoch:  82/1000 Discriminator Loss: 0.7782 Generator Loss: 1.4831\n",
            "Epoch:  83/1000 Discriminator Loss: 1.1600 Generator Loss: 1.4255\n",
            "Epoch:  84/1000 Discriminator Loss: 0.6988 Generator Loss: 1.6381\n",
            "Epoch:  85/1000 Discriminator Loss: 1.1849 Generator Loss: 1.4473\n",
            "Epoch:  86/1000 Discriminator Loss: 1.0235 Generator Loss: 1.2427\n",
            "Epoch:  87/1000 Discriminator Loss: 1.5938 Generator Loss: 1.5254\n",
            "Epoch:  88/1000 Discriminator Loss: 0.6670 Generator Loss: 1.2436\n",
            "Epoch:  89/1000 Discriminator Loss: 2.0142 Generator Loss: 1.3578\n",
            "Epoch:  90/1000 Discriminator Loss: 0.8924 Generator Loss: 1.6942\n",
            "Epoch:  91/1000 Discriminator Loss: 0.4719 Generator Loss: 1.8364\n",
            "Epoch:  92/1000 Discriminator Loss: 1.3646 Generator Loss: 1.2850\n",
            "Epoch:  93/1000 Discriminator Loss: 1.9948 Generator Loss: 1.5712\n",
            "Epoch:  94/1000 Discriminator Loss: 0.9383 Generator Loss: 2.1938\n",
            "Epoch:  95/1000 Discriminator Loss: 0.8522 Generator Loss: 1.5240\n",
            "Epoch:  96/1000 Discriminator Loss: 0.9232 Generator Loss: 1.6096\n",
            "Epoch:  97/1000 Discriminator Loss: 0.9116 Generator Loss: 1.4100\n",
            "Epoch:  98/1000 Discriminator Loss: 1.1329 Generator Loss: 1.1429\n",
            "Epoch:  99/1000 Discriminator Loss: 1.4711 Generator Loss: 1.0264\n",
            "Epoch: 100/1000 Discriminator Loss: 1.4385 Generator Loss: 0.9693\n",
            "Epoch: 101/1000 Discriminator Loss: 0.8403 Generator Loss: 1.5011\n",
            "Epoch: 102/1000 Discriminator Loss: 0.8719 Generator Loss: 1.3167\n",
            "Epoch: 103/1000 Discriminator Loss: 0.6742 Generator Loss: 1.6643\n",
            "Epoch: 104/1000 Discriminator Loss: 1.6230 Generator Loss: 1.4901\n",
            "Epoch: 105/1000 Discriminator Loss: 1.0977 Generator Loss: 1.2161\n",
            "Epoch: 106/1000 Discriminator Loss: 1.6914 Generator Loss: 1.2555\n",
            "Epoch: 107/1000 Discriminator Loss: 1.7789 Generator Loss: 0.8223\n",
            "Epoch: 108/1000 Discriminator Loss: 1.2546 Generator Loss: 1.0192\n",
            "Epoch: 109/1000 Discriminator Loss: 0.6189 Generator Loss: 1.6769\n",
            "Epoch: 110/1000 Discriminator Loss: 1.2625 Generator Loss: 1.1644\n",
            "Epoch: 111/1000 Discriminator Loss: 0.7448 Generator Loss: 1.0314\n",
            "Epoch: 112/1000 Discriminator Loss: 1.7117 Generator Loss: 0.9967\n",
            "Epoch: 113/1000 Discriminator Loss: 0.7995 Generator Loss: 1.4441\n",
            "Epoch: 114/1000 Discriminator Loss: 1.3709 Generator Loss: 1.0813\n",
            "Epoch: 115/1000 Discriminator Loss: 0.6864 Generator Loss: 1.6163\n",
            "Epoch: 116/1000 Discriminator Loss: 0.9496 Generator Loss: 1.7183\n",
            "Epoch: 117/1000 Discriminator Loss: 0.7733 Generator Loss: 1.7928\n",
            "Epoch: 118/1000 Discriminator Loss: 1.4340 Generator Loss: 1.1860\n",
            "Epoch: 119/1000 Discriminator Loss: 1.5974 Generator Loss: 1.3137\n",
            "Epoch: 120/1000 Discriminator Loss: 0.9713 Generator Loss: 1.2434\n",
            "Epoch: 121/1000 Discriminator Loss: 0.9933 Generator Loss: 1.3255\n",
            "Epoch: 122/1000 Discriminator Loss: 1.1170 Generator Loss: 1.6443\n",
            "Epoch: 123/1000 Discriminator Loss: 0.7742 Generator Loss: 2.0742\n",
            "Epoch: 124/1000 Discriminator Loss: 0.9215 Generator Loss: 1.3352\n",
            "Epoch: 125/1000 Discriminator Loss: 0.6555 Generator Loss: 1.7003\n",
            "Epoch: 126/1000 Discriminator Loss: 0.8256 Generator Loss: 1.6943\n",
            "Epoch: 127/1000 Discriminator Loss: 1.0421 Generator Loss: 0.9984\n",
            "Epoch: 128/1000 Discriminator Loss: 1.4121 Generator Loss: 0.8113\n",
            "Epoch: 129/1000 Discriminator Loss: 1.2423 Generator Loss: 1.0947\n",
            "Epoch: 130/1000 Discriminator Loss: 1.0037 Generator Loss: 1.2753\n",
            "Epoch: 131/1000 Discriminator Loss: 0.8747 Generator Loss: 1.4540\n",
            "Epoch: 132/1000 Discriminator Loss: 0.7672 Generator Loss: 2.6376\n",
            "Epoch: 133/1000 Discriminator Loss: 0.7463 Generator Loss: 2.0520\n",
            "Epoch: 134/1000 Discriminator Loss: 1.3268 Generator Loss: 0.7999\n",
            "Epoch: 135/1000 Discriminator Loss: 1.0663 Generator Loss: 1.1043\n",
            "Epoch: 136/1000 Discriminator Loss: 0.8388 Generator Loss: 1.2107\n",
            "Epoch: 137/1000 Discriminator Loss: 1.3316 Generator Loss: 0.9942\n",
            "Epoch: 138/1000 Discriminator Loss: 1.7709 Generator Loss: 1.2624\n",
            "Epoch: 139/1000 Discriminator Loss: 1.1488 Generator Loss: 1.1830\n",
            "Epoch: 140/1000 Discriminator Loss: 0.8123 Generator Loss: 1.5339\n",
            "Epoch: 141/1000 Discriminator Loss: 1.6808 Generator Loss: 0.8995\n",
            "Epoch: 142/1000 Discriminator Loss: 1.8275 Generator Loss: 1.0082\n",
            "Epoch: 143/1000 Discriminator Loss: 1.0761 Generator Loss: 1.2134\n",
            "Epoch: 144/1000 Discriminator Loss: 1.2730 Generator Loss: 1.1700\n",
            "Epoch: 145/1000 Discriminator Loss: 0.8229 Generator Loss: 1.2364\n",
            "Epoch: 146/1000 Discriminator Loss: 1.1115 Generator Loss: 1.1018\n",
            "Epoch: 147/1000 Discriminator Loss: 1.1194 Generator Loss: 1.5963\n",
            "Epoch: 148/1000 Discriminator Loss: 1.2574 Generator Loss: 1.2087\n",
            "Epoch: 149/1000 Discriminator Loss: 1.2790 Generator Loss: 1.1754\n",
            "Epoch: 150/1000 Discriminator Loss: 0.8817 Generator Loss: 1.2271\n",
            "Epoch: 151/1000 Discriminator Loss: 1.2986 Generator Loss: 0.9827\n",
            "Epoch: 152/1000 Discriminator Loss: 1.2527 Generator Loss: 1.0753\n",
            "Epoch: 153/1000 Discriminator Loss: 1.3850 Generator Loss: 0.7842\n",
            "Epoch: 154/1000 Discriminator Loss: 1.1999 Generator Loss: 1.0605\n",
            "Epoch: 155/1000 Discriminator Loss: 1.3452 Generator Loss: 1.2779\n",
            "Epoch: 156/1000 Discriminator Loss: 0.5558 Generator Loss: 2.0355\n",
            "Epoch: 157/1000 Discriminator Loss: 0.2761 Generator Loss: 2.3526\n",
            "Epoch: 158/1000 Discriminator Loss: 1.3466 Generator Loss: 1.1276\n",
            "Epoch: 159/1000 Discriminator Loss: 1.3310 Generator Loss: 0.8945\n",
            "Epoch: 160/1000 Discriminator Loss: 1.3524 Generator Loss: 1.2462\n",
            "Epoch: 161/1000 Discriminator Loss: 0.6413 Generator Loss: 1.9677\n",
            "Epoch: 162/1000 Discriminator Loss: 0.5028 Generator Loss: 1.7234\n",
            "Epoch: 163/1000 Discriminator Loss: 1.3242 Generator Loss: 1.2808\n",
            "Epoch: 164/1000 Discriminator Loss: 0.8569 Generator Loss: 1.2718\n",
            "Epoch: 165/1000 Discriminator Loss: 0.8353 Generator Loss: 1.6526\n",
            "Epoch: 166/1000 Discriminator Loss: 1.2620 Generator Loss: 1.0521\n",
            "Epoch: 167/1000 Discriminator Loss: 0.9339 Generator Loss: 1.1147\n",
            "Epoch: 168/1000 Discriminator Loss: 0.5833 Generator Loss: 1.6973\n",
            "Epoch: 169/1000 Discriminator Loss: 1.2518 Generator Loss: 1.0233\n",
            "Epoch: 170/1000 Discriminator Loss: 1.3271 Generator Loss: 1.0481\n",
            "Epoch: 171/1000 Discriminator Loss: 0.5715 Generator Loss: 1.5575\n",
            "Epoch: 172/1000 Discriminator Loss: 1.0158 Generator Loss: 1.1780\n",
            "Epoch: 173/1000 Discriminator Loss: 0.7894 Generator Loss: 1.3427\n",
            "Epoch: 174/1000 Discriminator Loss: 0.7321 Generator Loss: 1.1862\n",
            "Epoch: 175/1000 Discriminator Loss: 0.7868 Generator Loss: 1.8700\n",
            "Epoch: 176/1000 Discriminator Loss: 1.3572 Generator Loss: 1.2293\n",
            "Epoch: 177/1000 Discriminator Loss: 1.4981 Generator Loss: 0.8229\n",
            "Epoch: 178/1000 Discriminator Loss: 0.6298 Generator Loss: 1.7927\n",
            "Epoch: 179/1000 Discriminator Loss: 0.9592 Generator Loss: 1.6173\n",
            "Epoch: 180/1000 Discriminator Loss: 1.1958 Generator Loss: 1.5129\n",
            "Epoch: 181/1000 Discriminator Loss: 1.2478 Generator Loss: 1.3028\n",
            "Epoch: 182/1000 Discriminator Loss: 1.7013 Generator Loss: 0.8864\n",
            "Epoch: 183/1000 Discriminator Loss: 0.5472 Generator Loss: 1.6518\n",
            "Epoch: 184/1000 Discriminator Loss: 1.2103 Generator Loss: 0.9736\n",
            "Epoch: 185/1000 Discriminator Loss: 0.7733 Generator Loss: 1.1422\n",
            "Epoch: 186/1000 Discriminator Loss: 0.9226 Generator Loss: 1.3005\n",
            "Epoch: 187/1000 Discriminator Loss: 1.6558 Generator Loss: 1.0882\n",
            "Epoch: 188/1000 Discriminator Loss: 0.8161 Generator Loss: 0.8757\n",
            "Epoch: 189/1000 Discriminator Loss: 1.0168 Generator Loss: 1.1953\n",
            "Epoch: 190/1000 Discriminator Loss: 1.5395 Generator Loss: 0.9589\n",
            "Epoch: 191/1000 Discriminator Loss: 0.3916 Generator Loss: 2.2931\n",
            "Epoch: 192/1000 Discriminator Loss: 1.4214 Generator Loss: 1.0787\n",
            "Epoch: 193/1000 Discriminator Loss: 1.2436 Generator Loss: 1.6627\n",
            "Epoch: 194/1000 Discriminator Loss: 1.0474 Generator Loss: 1.4180\n",
            "Epoch: 195/1000 Discriminator Loss: 0.8456 Generator Loss: 2.3844\n",
            "Epoch: 196/1000 Discriminator Loss: 1.9212 Generator Loss: 1.5255\n",
            "Epoch: 197/1000 Discriminator Loss: 0.4571 Generator Loss: 2.1896\n",
            "Epoch: 198/1000 Discriminator Loss: 0.8742 Generator Loss: 1.1833\n",
            "Epoch: 199/1000 Discriminator Loss: 0.7544 Generator Loss: 1.8354\n",
            "Epoch: 200/1000 Discriminator Loss: 0.9729 Generator Loss: 1.3680\n",
            "Epoch: 201/1000 Discriminator Loss: 1.2425 Generator Loss: 1.3429\n",
            "Epoch: 202/1000 Discriminator Loss: 1.2127 Generator Loss: 1.2620\n",
            "Epoch: 203/1000 Discriminator Loss: 1.2334 Generator Loss: 1.9566\n",
            "Epoch: 204/1000 Discriminator Loss: 0.6338 Generator Loss: 2.0713\n",
            "Epoch: 205/1000 Discriminator Loss: 0.4502 Generator Loss: 1.9271\n",
            "Epoch: 206/1000 Discriminator Loss: 0.3849 Generator Loss: 1.9264\n",
            "Epoch: 207/1000 Discriminator Loss: 1.3243 Generator Loss: 0.8632\n",
            "Epoch: 208/1000 Discriminator Loss: 0.9295 Generator Loss: 1.6236\n",
            "Epoch: 209/1000 Discriminator Loss: 1.7076 Generator Loss: 1.0140\n",
            "Epoch: 210/1000 Discriminator Loss: 0.8038 Generator Loss: 1.5329\n",
            "Epoch: 211/1000 Discriminator Loss: 1.1275 Generator Loss: 0.8880\n",
            "Epoch: 212/1000 Discriminator Loss: 0.9505 Generator Loss: 1.5652\n",
            "Epoch: 213/1000 Discriminator Loss: 1.3382 Generator Loss: 0.9543\n",
            "Epoch: 214/1000 Discriminator Loss: 1.0358 Generator Loss: 1.0969\n",
            "Epoch: 215/1000 Discriminator Loss: 0.8399 Generator Loss: 1.9686\n",
            "Epoch: 216/1000 Discriminator Loss: 0.9064 Generator Loss: 1.4951\n",
            "Epoch: 217/1000 Discriminator Loss: 1.4023 Generator Loss: 1.2923\n",
            "Epoch: 218/1000 Discriminator Loss: 2.6117 Generator Loss: 1.0149\n",
            "Epoch: 219/1000 Discriminator Loss: 0.9431 Generator Loss: 1.9113\n",
            "Epoch: 220/1000 Discriminator Loss: 1.8379 Generator Loss: 1.1511\n",
            "Epoch: 221/1000 Discriminator Loss: 0.5481 Generator Loss: 2.1676\n",
            "Epoch: 222/1000 Discriminator Loss: 1.3048 Generator Loss: 1.2216\n",
            "Epoch: 223/1000 Discriminator Loss: 1.2646 Generator Loss: 1.2449\n",
            "Epoch: 224/1000 Discriminator Loss: 1.5619 Generator Loss: 1.3900\n",
            "Epoch: 225/1000 Discriminator Loss: 1.5946 Generator Loss: 1.4547\n",
            "Epoch: 226/1000 Discriminator Loss: 0.5949 Generator Loss: 1.4835\n",
            "Epoch: 227/1000 Discriminator Loss: 0.9710 Generator Loss: 2.2718\n",
            "Epoch: 228/1000 Discriminator Loss: 1.5352 Generator Loss: 1.1836\n",
            "Epoch: 229/1000 Discriminator Loss: 1.2090 Generator Loss: 1.2558\n",
            "Epoch: 230/1000 Discriminator Loss: 0.5213 Generator Loss: 1.4671\n",
            "Epoch: 231/1000 Discriminator Loss: 1.6677 Generator Loss: 0.9920\n",
            "Epoch: 232/1000 Discriminator Loss: 1.3698 Generator Loss: 0.8472\n",
            "Epoch: 233/1000 Discriminator Loss: 1.6431 Generator Loss: 1.0038\n",
            "Epoch: 234/1000 Discriminator Loss: 0.8393 Generator Loss: 1.6709\n",
            "Epoch: 235/1000 Discriminator Loss: 1.3048 Generator Loss: 1.3769\n",
            "Epoch: 236/1000 Discriminator Loss: 1.0676 Generator Loss: 1.4858\n",
            "Epoch: 237/1000 Discriminator Loss: 1.1603 Generator Loss: 1.0807\n",
            "Epoch: 238/1000 Discriminator Loss: 0.7508 Generator Loss: 1.7366\n",
            "Epoch: 239/1000 Discriminator Loss: 1.4263 Generator Loss: 1.3550\n",
            "Epoch: 240/1000 Discriminator Loss: 0.6744 Generator Loss: 1.5208\n",
            "Epoch: 241/1000 Discriminator Loss: 1.8176 Generator Loss: 1.0408\n",
            "Epoch: 242/1000 Discriminator Loss: 1.5850 Generator Loss: 1.5421\n",
            "Epoch: 243/1000 Discriminator Loss: 0.8692 Generator Loss: 2.0067\n",
            "Epoch: 244/1000 Discriminator Loss: 1.4688 Generator Loss: 1.7842\n",
            "Epoch: 245/1000 Discriminator Loss: 1.3009 Generator Loss: 0.8958\n",
            "Epoch: 246/1000 Discriminator Loss: 1.1007 Generator Loss: 0.8578\n",
            "Epoch: 247/1000 Discriminator Loss: 0.9611 Generator Loss: 1.5800\n",
            "Epoch: 248/1000 Discriminator Loss: 0.8563 Generator Loss: 1.3434\n",
            "Epoch: 249/1000 Discriminator Loss: 0.9414 Generator Loss: 1.2661\n",
            "Epoch: 250/1000 Discriminator Loss: 1.2538 Generator Loss: 1.1700\n",
            "Epoch: 251/1000 Discriminator Loss: 0.9091 Generator Loss: 1.8127\n",
            "Epoch: 252/1000 Discriminator Loss: 1.4283 Generator Loss: 0.8099\n",
            "Epoch: 253/1000 Discriminator Loss: 0.9190 Generator Loss: 1.7802\n",
            "Epoch: 254/1000 Discriminator Loss: 0.8809 Generator Loss: 1.2837\n",
            "Epoch: 255/1000 Discriminator Loss: 1.0270 Generator Loss: 1.7468\n",
            "Epoch: 256/1000 Discriminator Loss: 0.9316 Generator Loss: 1.3647\n",
            "Epoch: 257/1000 Discriminator Loss: 2.3103 Generator Loss: 1.0303\n",
            "Epoch: 258/1000 Discriminator Loss: 1.1118 Generator Loss: 1.1751\n",
            "Epoch: 259/1000 Discriminator Loss: 1.0767 Generator Loss: 1.2275\n",
            "Epoch: 260/1000 Discriminator Loss: 1.0624 Generator Loss: 1.1701\n",
            "Epoch: 261/1000 Discriminator Loss: 1.3562 Generator Loss: 0.7282\n",
            "Epoch: 262/1000 Discriminator Loss: 1.1860 Generator Loss: 1.0693\n",
            "Epoch: 263/1000 Discriminator Loss: 1.0009 Generator Loss: 1.4101\n",
            "Epoch: 264/1000 Discriminator Loss: 0.9879 Generator Loss: 1.3968\n",
            "Epoch: 265/1000 Discriminator Loss: 1.0964 Generator Loss: 1.1162\n",
            "Epoch: 266/1000 Discriminator Loss: 1.2977 Generator Loss: 1.1114\n",
            "Epoch: 267/1000 Discriminator Loss: 1.0898 Generator Loss: 1.0138\n",
            "Epoch: 268/1000 Discriminator Loss: 0.9309 Generator Loss: 1.0714\n",
            "Epoch: 269/1000 Discriminator Loss: 1.2095 Generator Loss: 0.9282\n",
            "Epoch: 270/1000 Discriminator Loss: 0.8979 Generator Loss: 1.2747\n",
            "Epoch: 271/1000 Discriminator Loss: 1.0294 Generator Loss: 1.3721\n",
            "Epoch: 272/1000 Discriminator Loss: 0.9467 Generator Loss: 2.1240\n",
            "Epoch: 273/1000 Discriminator Loss: 0.9318 Generator Loss: 1.2262\n",
            "Epoch: 274/1000 Discriminator Loss: 1.5514 Generator Loss: 0.9941\n",
            "Epoch: 275/1000 Discriminator Loss: 1.2465 Generator Loss: 1.3015\n",
            "Epoch: 276/1000 Discriminator Loss: 1.4567 Generator Loss: 1.1981\n",
            "Epoch: 277/1000 Discriminator Loss: 1.2445 Generator Loss: 1.2819\n",
            "Epoch: 278/1000 Discriminator Loss: 1.4180 Generator Loss: 0.9495\n",
            "Epoch: 279/1000 Discriminator Loss: 1.2549 Generator Loss: 0.8523\n",
            "Epoch: 280/1000 Discriminator Loss: 1.0818 Generator Loss: 1.3762\n",
            "Epoch: 281/1000 Discriminator Loss: 0.4541 Generator Loss: 2.1335\n",
            "Epoch: 282/1000 Discriminator Loss: 0.7371 Generator Loss: 1.4428\n",
            "Epoch: 283/1000 Discriminator Loss: 1.9634 Generator Loss: 0.7230\n",
            "Epoch: 284/1000 Discriminator Loss: 1.1838 Generator Loss: 0.8869\n",
            "Epoch: 285/1000 Discriminator Loss: 1.4218 Generator Loss: 0.9808\n",
            "Epoch: 286/1000 Discriminator Loss: 1.2535 Generator Loss: 1.4367\n",
            "Epoch: 287/1000 Discriminator Loss: 1.1990 Generator Loss: 0.9076\n",
            "Epoch: 288/1000 Discriminator Loss: 0.8864 Generator Loss: 1.0390\n",
            "Epoch: 289/1000 Discriminator Loss: 1.1623 Generator Loss: 1.0071\n",
            "Epoch: 290/1000 Discriminator Loss: 0.6873 Generator Loss: 1.2298\n",
            "Epoch: 291/1000 Discriminator Loss: 0.5885 Generator Loss: 1.4411\n",
            "Epoch: 292/1000 Discriminator Loss: 1.3855 Generator Loss: 1.2305\n",
            "Epoch: 293/1000 Discriminator Loss: 1.1177 Generator Loss: 1.2029\n",
            "Epoch: 294/1000 Discriminator Loss: 1.0489 Generator Loss: 1.0584\n",
            "Epoch: 295/1000 Discriminator Loss: 1.2747 Generator Loss: 1.3828\n",
            "Epoch: 296/1000 Discriminator Loss: 1.8138 Generator Loss: 1.2624\n",
            "Epoch: 297/1000 Discriminator Loss: 0.4966 Generator Loss: 2.4767\n",
            "Epoch: 298/1000 Discriminator Loss: 1.6639 Generator Loss: 0.9420\n",
            "Epoch: 299/1000 Discriminator Loss: 1.4291 Generator Loss: 0.9565\n",
            "Epoch: 300/1000 Discriminator Loss: 1.3785 Generator Loss: 1.2188\n",
            "Epoch: 301/1000 Discriminator Loss: 0.7197 Generator Loss: 1.1535\n",
            "Epoch: 302/1000 Discriminator Loss: 1.6662 Generator Loss: 0.8859\n",
            "Epoch: 303/1000 Discriminator Loss: 1.4316 Generator Loss: 0.9296\n",
            "Epoch: 304/1000 Discriminator Loss: 1.2010 Generator Loss: 1.1793\n",
            "Epoch: 305/1000 Discriminator Loss: 1.4251 Generator Loss: 1.4933\n",
            "Epoch: 306/1000 Discriminator Loss: 0.9620 Generator Loss: 1.2364\n",
            "Epoch: 307/1000 Discriminator Loss: 1.6624 Generator Loss: 0.9466\n",
            "Epoch: 308/1000 Discriminator Loss: 0.9248 Generator Loss: 1.4017\n",
            "Epoch: 309/1000 Discriminator Loss: 1.8531 Generator Loss: 0.5610\n",
            "Epoch: 310/1000 Discriminator Loss: 1.1003 Generator Loss: 0.9827\n",
            "Epoch: 311/1000 Discriminator Loss: 1.5038 Generator Loss: 0.7998\n",
            "Epoch: 312/1000 Discriminator Loss: 1.7074 Generator Loss: 0.9244\n",
            "Epoch: 313/1000 Discriminator Loss: 1.2080 Generator Loss: 0.9084\n",
            "Epoch: 314/1000 Discriminator Loss: 1.2449 Generator Loss: 1.4512\n",
            "Epoch: 315/1000 Discriminator Loss: 1.0815 Generator Loss: 1.5101\n",
            "Epoch: 316/1000 Discriminator Loss: 1.0099 Generator Loss: 1.3660\n",
            "Epoch: 317/1000 Discriminator Loss: 1.7646 Generator Loss: 0.8310\n",
            "Epoch: 318/1000 Discriminator Loss: 1.7714 Generator Loss: 0.9072\n",
            "Epoch: 319/1000 Discriminator Loss: 1.2423 Generator Loss: 0.9527\n",
            "Epoch: 320/1000 Discriminator Loss: 1.2651 Generator Loss: 0.8945\n",
            "Epoch: 321/1000 Discriminator Loss: 0.9018 Generator Loss: 1.2955\n",
            "Epoch: 322/1000 Discriminator Loss: 0.9229 Generator Loss: 1.0685\n",
            "Epoch: 323/1000 Discriminator Loss: 1.7697 Generator Loss: 1.1037\n",
            "Epoch: 324/1000 Discriminator Loss: 1.0656 Generator Loss: 1.1677\n",
            "Epoch: 325/1000 Discriminator Loss: 1.3758 Generator Loss: 0.9765\n",
            "Epoch: 326/1000 Discriminator Loss: 1.2787 Generator Loss: 1.2368\n",
            "Epoch: 327/1000 Discriminator Loss: 0.6633 Generator Loss: 1.2823\n",
            "Epoch: 328/1000 Discriminator Loss: 1.6648 Generator Loss: 1.1158\n",
            "Epoch: 329/1000 Discriminator Loss: 1.1469 Generator Loss: 0.8788\n",
            "Epoch: 330/1000 Discriminator Loss: 1.4676 Generator Loss: 0.6953\n",
            "Epoch: 331/1000 Discriminator Loss: 1.3778 Generator Loss: 0.8590\n",
            "Epoch: 332/1000 Discriminator Loss: 1.2032 Generator Loss: 0.9921\n",
            "Epoch: 333/1000 Discriminator Loss: 1.5851 Generator Loss: 1.1057\n",
            "Epoch: 334/1000 Discriminator Loss: 1.8392 Generator Loss: 1.2538\n",
            "Epoch: 335/1000 Discriminator Loss: 0.5748 Generator Loss: 1.5349\n",
            "Epoch: 336/1000 Discriminator Loss: 1.3662 Generator Loss: 1.0441\n",
            "Epoch: 337/1000 Discriminator Loss: 1.7261 Generator Loss: 1.0597\n",
            "Epoch: 338/1000 Discriminator Loss: 1.0497 Generator Loss: 1.1686\n",
            "Epoch: 339/1000 Discriminator Loss: 1.2415 Generator Loss: 0.8487\n",
            "Epoch: 340/1000 Discriminator Loss: 1.1992 Generator Loss: 1.0153\n",
            "Epoch: 341/1000 Discriminator Loss: 1.6357 Generator Loss: 1.1064\n",
            "Epoch: 342/1000 Discriminator Loss: 0.9277 Generator Loss: 1.2290\n",
            "Epoch: 343/1000 Discriminator Loss: 0.9262 Generator Loss: 1.2221\n",
            "Epoch: 344/1000 Discriminator Loss: 0.9290 Generator Loss: 1.5570\n",
            "Epoch: 345/1000 Discriminator Loss: 1.0703 Generator Loss: 1.2963\n",
            "Epoch: 346/1000 Discriminator Loss: 1.3041 Generator Loss: 1.1544\n",
            "Epoch: 347/1000 Discriminator Loss: 1.5652 Generator Loss: 1.0561\n",
            "Epoch: 348/1000 Discriminator Loss: 1.6580 Generator Loss: 0.9370\n",
            "Epoch: 349/1000 Discriminator Loss: 0.9305 Generator Loss: 1.0588\n",
            "Epoch: 350/1000 Discriminator Loss: 1.3019 Generator Loss: 0.8086\n",
            "Epoch: 351/1000 Discriminator Loss: 1.0089 Generator Loss: 1.2398\n",
            "Epoch: 352/1000 Discriminator Loss: 0.9812 Generator Loss: 1.1999\n",
            "Epoch: 353/1000 Discriminator Loss: 1.5696 Generator Loss: 1.0711\n",
            "Epoch: 354/1000 Discriminator Loss: 0.7879 Generator Loss: 1.3383\n",
            "Epoch: 355/1000 Discriminator Loss: 1.6521 Generator Loss: 1.1777\n",
            "Epoch: 356/1000 Discriminator Loss: 1.5628 Generator Loss: 0.9738\n",
            "Epoch: 357/1000 Discriminator Loss: 1.3855 Generator Loss: 1.0393\n",
            "Epoch: 358/1000 Discriminator Loss: 1.6549 Generator Loss: 1.1068\n",
            "Epoch: 359/1000 Discriminator Loss: 1.5435 Generator Loss: 1.3252\n",
            "Epoch: 360/1000 Discriminator Loss: 1.2024 Generator Loss: 1.2860\n",
            "Epoch: 361/1000 Discriminator Loss: 1.4202 Generator Loss: 1.1689\n",
            "Epoch: 362/1000 Discriminator Loss: 1.6719 Generator Loss: 0.8483\n",
            "Epoch: 363/1000 Discriminator Loss: 1.3583 Generator Loss: 0.8769\n",
            "Epoch: 364/1000 Discriminator Loss: 0.7545 Generator Loss: 1.5194\n",
            "Epoch: 365/1000 Discriminator Loss: 1.3047 Generator Loss: 0.9408\n",
            "Epoch: 366/1000 Discriminator Loss: 1.8503 Generator Loss: 1.0527\n",
            "Epoch: 367/1000 Discriminator Loss: 1.1807 Generator Loss: 0.9664\n",
            "Epoch: 368/1000 Discriminator Loss: 1.4913 Generator Loss: 1.1646\n",
            "Epoch: 369/1000 Discriminator Loss: 1.1721 Generator Loss: 1.0434\n",
            "Epoch: 370/1000 Discriminator Loss: 1.6178 Generator Loss: 0.9525\n",
            "Epoch: 371/1000 Discriminator Loss: 1.3675 Generator Loss: 0.8177\n",
            "Epoch: 372/1000 Discriminator Loss: 0.7509 Generator Loss: 1.4107\n",
            "Epoch: 373/1000 Discriminator Loss: 1.0975 Generator Loss: 1.4310\n",
            "Epoch: 374/1000 Discriminator Loss: 1.0580 Generator Loss: 1.0890\n",
            "Epoch: 375/1000 Discriminator Loss: 1.0912 Generator Loss: 1.2836\n",
            "Epoch: 376/1000 Discriminator Loss: 1.3722 Generator Loss: 1.0938\n",
            "Epoch: 377/1000 Discriminator Loss: 1.8702 Generator Loss: 0.6010\n",
            "Epoch: 378/1000 Discriminator Loss: 1.3510 Generator Loss: 1.0742\n",
            "Epoch: 379/1000 Discriminator Loss: 1.4504 Generator Loss: 0.9752\n",
            "Epoch: 380/1000 Discriminator Loss: 0.5427 Generator Loss: 1.2833\n",
            "Epoch: 381/1000 Discriminator Loss: 0.8749 Generator Loss: 1.6370\n",
            "Epoch: 382/1000 Discriminator Loss: 1.6247 Generator Loss: 1.6025\n",
            "Epoch: 383/1000 Discriminator Loss: 0.8217 Generator Loss: 1.9016\n",
            "Epoch: 384/1000 Discriminator Loss: 0.6124 Generator Loss: 1.3374\n",
            "Epoch: 385/1000 Discriminator Loss: 1.2932 Generator Loss: 1.0397\n",
            "Epoch: 386/1000 Discriminator Loss: 1.3579 Generator Loss: 1.2646\n",
            "Epoch: 387/1000 Discriminator Loss: 1.6599 Generator Loss: 0.8650\n",
            "Epoch: 388/1000 Discriminator Loss: 1.0698 Generator Loss: 1.3445\n",
            "Epoch: 389/1000 Discriminator Loss: 1.1797 Generator Loss: 1.0516\n",
            "Epoch: 390/1000 Discriminator Loss: 0.9930 Generator Loss: 1.5732\n",
            "Epoch: 391/1000 Discriminator Loss: 1.2465 Generator Loss: 1.2358\n",
            "Epoch: 392/1000 Discriminator Loss: 0.9935 Generator Loss: 1.1730\n",
            "Epoch: 393/1000 Discriminator Loss: 2.0875 Generator Loss: 0.8317\n",
            "Epoch: 394/1000 Discriminator Loss: 0.9216 Generator Loss: 1.1752\n",
            "Epoch: 395/1000 Discriminator Loss: 1.3393 Generator Loss: 1.2310\n",
            "Epoch: 396/1000 Discriminator Loss: 0.9997 Generator Loss: 1.4043\n",
            "Epoch: 397/1000 Discriminator Loss: 1.4810 Generator Loss: 1.3402\n",
            "Epoch: 398/1000 Discriminator Loss: 1.7387 Generator Loss: 0.7733\n",
            "Epoch: 399/1000 Discriminator Loss: 1.1616 Generator Loss: 1.0818\n",
            "Epoch: 400/1000 Discriminator Loss: 0.9861 Generator Loss: 1.2821\n",
            "Epoch: 401/1000 Discriminator Loss: 1.0494 Generator Loss: 1.3344\n",
            "Epoch: 402/1000 Discriminator Loss: 1.2740 Generator Loss: 1.3164\n",
            "Epoch: 403/1000 Discriminator Loss: 0.8636 Generator Loss: 1.3978\n",
            "Epoch: 404/1000 Discriminator Loss: 1.2294 Generator Loss: 1.1516\n",
            "Epoch: 405/1000 Discriminator Loss: 1.1232 Generator Loss: 0.9306\n",
            "Epoch: 406/1000 Discriminator Loss: 1.2230 Generator Loss: 1.3504\n",
            "Epoch: 407/1000 Discriminator Loss: 1.3699 Generator Loss: 1.0099\n",
            "Epoch: 408/1000 Discriminator Loss: 1.5152 Generator Loss: 1.0754\n",
            "Epoch: 409/1000 Discriminator Loss: 1.0797 Generator Loss: 1.1657\n",
            "Epoch: 410/1000 Discriminator Loss: 1.0586 Generator Loss: 1.8859\n",
            "Epoch: 411/1000 Discriminator Loss: 1.2803 Generator Loss: 1.4023\n",
            "Epoch: 412/1000 Discriminator Loss: 0.8597 Generator Loss: 1.2201\n",
            "Epoch: 413/1000 Discriminator Loss: 0.9499 Generator Loss: 1.1543\n",
            "Epoch: 414/1000 Discriminator Loss: 1.1579 Generator Loss: 1.4875\n",
            "Epoch: 415/1000 Discriminator Loss: 1.1985 Generator Loss: 1.1389\n",
            "Epoch: 416/1000 Discriminator Loss: 1.2194 Generator Loss: 1.1261\n",
            "Epoch: 417/1000 Discriminator Loss: 0.7047 Generator Loss: 1.4420\n",
            "Epoch: 418/1000 Discriminator Loss: 1.5813 Generator Loss: 0.9081\n",
            "Epoch: 419/1000 Discriminator Loss: 1.6631 Generator Loss: 0.8549\n",
            "Epoch: 420/1000 Discriminator Loss: 0.5518 Generator Loss: 1.8483\n",
            "Epoch: 421/1000 Discriminator Loss: 2.1233 Generator Loss: 0.8743\n",
            "Epoch: 422/1000 Discriminator Loss: 0.4445 Generator Loss: 1.7988\n",
            "Epoch: 423/1000 Discriminator Loss: 0.3954 Generator Loss: 2.1317\n",
            "Epoch: 424/1000 Discriminator Loss: 0.7657 Generator Loss: 1.2831\n",
            "Epoch: 425/1000 Discriminator Loss: 1.5262 Generator Loss: 0.9125\n",
            "Epoch: 426/1000 Discriminator Loss: 0.9266 Generator Loss: 1.1883\n",
            "Epoch: 427/1000 Discriminator Loss: 0.8075 Generator Loss: 1.2181\n",
            "Epoch: 428/1000 Discriminator Loss: 1.4615 Generator Loss: 0.9521\n",
            "Epoch: 429/1000 Discriminator Loss: 1.0194 Generator Loss: 1.1342\n",
            "Epoch: 430/1000 Discriminator Loss: 0.9314 Generator Loss: 1.3753\n",
            "Epoch: 431/1000 Discriminator Loss: 1.6925 Generator Loss: 1.0405\n",
            "Epoch: 432/1000 Discriminator Loss: 1.3588 Generator Loss: 1.1558\n",
            "Epoch: 433/1000 Discriminator Loss: 1.4867 Generator Loss: 0.9438\n",
            "Epoch: 434/1000 Discriminator Loss: 1.1525 Generator Loss: 1.0500\n",
            "Epoch: 435/1000 Discriminator Loss: 1.0568 Generator Loss: 1.5293\n",
            "Epoch: 436/1000 Discriminator Loss: 1.4827 Generator Loss: 0.7968\n",
            "Epoch: 437/1000 Discriminator Loss: 1.7366 Generator Loss: 0.5355\n",
            "Epoch: 438/1000 Discriminator Loss: 1.1525 Generator Loss: 1.1279\n",
            "Epoch: 439/1000 Discriminator Loss: 1.7620 Generator Loss: 1.0837\n",
            "Epoch: 440/1000 Discriminator Loss: 1.0171 Generator Loss: 1.3643\n",
            "Epoch: 441/1000 Discriminator Loss: 1.3406 Generator Loss: 0.8067\n",
            "Epoch: 442/1000 Discriminator Loss: 1.4140 Generator Loss: 0.9283\n",
            "Epoch: 443/1000 Discriminator Loss: 0.9646 Generator Loss: 1.1140\n",
            "Epoch: 444/1000 Discriminator Loss: 2.0412 Generator Loss: 1.2831\n",
            "Epoch: 445/1000 Discriminator Loss: 1.5523 Generator Loss: 0.9439\n",
            "Epoch: 446/1000 Discriminator Loss: 1.2619 Generator Loss: 0.9514\n",
            "Epoch: 447/1000 Discriminator Loss: 1.3607 Generator Loss: 0.8861\n",
            "Epoch: 448/1000 Discriminator Loss: 1.5013 Generator Loss: 1.0399\n",
            "Epoch: 449/1000 Discriminator Loss: 1.2193 Generator Loss: 0.9558\n",
            "Epoch: 450/1000 Discriminator Loss: 1.4080 Generator Loss: 1.0759\n",
            "Epoch: 451/1000 Discriminator Loss: 1.3356 Generator Loss: 1.0625\n",
            "Epoch: 452/1000 Discriminator Loss: 0.8014 Generator Loss: 1.2020\n",
            "Epoch: 453/1000 Discriminator Loss: 1.8243 Generator Loss: 0.6686\n",
            "Epoch: 454/1000 Discriminator Loss: 1.6758 Generator Loss: 1.1557\n",
            "Epoch: 455/1000 Discriminator Loss: 1.5065 Generator Loss: 0.9095\n",
            "Epoch: 456/1000 Discriminator Loss: 1.1749 Generator Loss: 0.8728\n",
            "Epoch: 457/1000 Discriminator Loss: 1.2736 Generator Loss: 1.1599\n",
            "Epoch: 458/1000 Discriminator Loss: 0.9471 Generator Loss: 1.2577\n",
            "Epoch: 459/1000 Discriminator Loss: 1.8511 Generator Loss: 1.2102\n",
            "Epoch: 460/1000 Discriminator Loss: 1.1425 Generator Loss: 1.0744\n",
            "Epoch: 461/1000 Discriminator Loss: 0.9064 Generator Loss: 1.4651\n",
            "Epoch: 462/1000 Discriminator Loss: 0.8526 Generator Loss: 1.6716\n",
            "Epoch: 463/1000 Discriminator Loss: 1.2823 Generator Loss: 0.8570\n",
            "Epoch: 464/1000 Discriminator Loss: 1.0284 Generator Loss: 1.1139\n",
            "Epoch: 465/1000 Discriminator Loss: 1.6753 Generator Loss: 0.8050\n",
            "Epoch: 466/1000 Discriminator Loss: 1.2211 Generator Loss: 0.8487\n",
            "Epoch: 467/1000 Discriminator Loss: 1.4944 Generator Loss: 1.2092\n",
            "Epoch: 468/1000 Discriminator Loss: 1.4808 Generator Loss: 0.9359\n",
            "Epoch: 469/1000 Discriminator Loss: 1.0964 Generator Loss: 1.2082\n",
            "Epoch: 470/1000 Discriminator Loss: 1.6113 Generator Loss: 1.2347\n",
            "Epoch: 471/1000 Discriminator Loss: 1.0488 Generator Loss: 1.0615\n",
            "Epoch: 472/1000 Discriminator Loss: 1.5851 Generator Loss: 1.1374\n",
            "Epoch: 473/1000 Discriminator Loss: 0.9784 Generator Loss: 1.0747\n",
            "Epoch: 474/1000 Discriminator Loss: 0.7950 Generator Loss: 1.1772\n",
            "Epoch: 475/1000 Discriminator Loss: 1.1627 Generator Loss: 1.4448\n",
            "Epoch: 476/1000 Discriminator Loss: 1.4285 Generator Loss: 1.1897\n",
            "Epoch: 477/1000 Discriminator Loss: 1.8027 Generator Loss: 1.6051\n",
            "Epoch: 478/1000 Discriminator Loss: 1.0830 Generator Loss: 0.9329\n",
            "Epoch: 479/1000 Discriminator Loss: 1.2269 Generator Loss: 1.3099\n",
            "Epoch: 480/1000 Discriminator Loss: 0.8133 Generator Loss: 1.1049\n",
            "Epoch: 481/1000 Discriminator Loss: 1.4643 Generator Loss: 0.9845\n",
            "Epoch: 482/1000 Discriminator Loss: 1.2045 Generator Loss: 1.0578\n",
            "Epoch: 483/1000 Discriminator Loss: 1.3480 Generator Loss: 0.9783\n",
            "Epoch: 484/1000 Discriminator Loss: 0.6606 Generator Loss: 1.4502\n",
            "Epoch: 485/1000 Discriminator Loss: 0.9787 Generator Loss: 1.2297\n",
            "Epoch: 486/1000 Discriminator Loss: 1.2317 Generator Loss: 1.0800\n",
            "Epoch: 487/1000 Discriminator Loss: 1.2177 Generator Loss: 0.7896\n",
            "Epoch: 488/1000 Discriminator Loss: 1.1373 Generator Loss: 1.3724\n",
            "Epoch: 489/1000 Discriminator Loss: 1.2867 Generator Loss: 0.9369\n",
            "Epoch: 490/1000 Discriminator Loss: 1.2449 Generator Loss: 0.8768\n",
            "Epoch: 491/1000 Discriminator Loss: 1.2218 Generator Loss: 1.0154\n",
            "Epoch: 492/1000 Discriminator Loss: 1.6202 Generator Loss: 0.6856\n",
            "Epoch: 493/1000 Discriminator Loss: 0.9835 Generator Loss: 1.0414\n",
            "Epoch: 494/1000 Discriminator Loss: 1.5204 Generator Loss: 0.9088\n",
            "Epoch: 495/1000 Discriminator Loss: 1.2120 Generator Loss: 0.9237\n",
            "Epoch: 496/1000 Discriminator Loss: 1.0242 Generator Loss: 1.1212\n",
            "Epoch: 497/1000 Discriminator Loss: 2.1631 Generator Loss: 0.9038\n",
            "Epoch: 498/1000 Discriminator Loss: 1.2775 Generator Loss: 1.0494\n",
            "Epoch: 499/1000 Discriminator Loss: 0.8724 Generator Loss: 1.0351\n",
            "Epoch: 500/1000 Discriminator Loss: 1.1805 Generator Loss: 1.0062\n",
            "Epoch: 501/1000 Discriminator Loss: 1.3933 Generator Loss: 1.1146\n",
            "Epoch: 502/1000 Discriminator Loss: 1.6372 Generator Loss: 0.9685\n",
            "Epoch: 503/1000 Discriminator Loss: 1.2742 Generator Loss: 1.1278\n",
            "Epoch: 504/1000 Discriminator Loss: 0.6947 Generator Loss: 1.5860\n",
            "Epoch: 505/1000 Discriminator Loss: 0.8662 Generator Loss: 1.5180\n",
            "Epoch: 506/1000 Discriminator Loss: 0.8319 Generator Loss: 1.1950\n",
            "Epoch: 507/1000 Discriminator Loss: 1.7417 Generator Loss: 1.0137\n",
            "Epoch: 508/1000 Discriminator Loss: 1.3204 Generator Loss: 1.1101\n",
            "Epoch: 509/1000 Discriminator Loss: 1.3876 Generator Loss: 0.9937\n",
            "Epoch: 510/1000 Discriminator Loss: 1.6185 Generator Loss: 0.8026\n",
            "Epoch: 511/1000 Discriminator Loss: 1.3315 Generator Loss: 0.7274\n",
            "Epoch: 512/1000 Discriminator Loss: 1.8639 Generator Loss: 1.1133\n",
            "Epoch: 513/1000 Discriminator Loss: 1.2553 Generator Loss: 1.1403\n",
            "Epoch: 514/1000 Discriminator Loss: 0.7217 Generator Loss: 1.4077\n",
            "Epoch: 515/1000 Discriminator Loss: 0.7487 Generator Loss: 1.5907\n",
            "Epoch: 516/1000 Discriminator Loss: 1.1989 Generator Loss: 1.4397\n",
            "Epoch: 517/1000 Discriminator Loss: 1.4267 Generator Loss: 1.0661\n",
            "Epoch: 518/1000 Discriminator Loss: 1.5244 Generator Loss: 0.8401\n",
            "Epoch: 519/1000 Discriminator Loss: 1.4101 Generator Loss: 0.8148\n",
            "Epoch: 520/1000 Discriminator Loss: 1.3316 Generator Loss: 1.2304\n",
            "Epoch: 521/1000 Discriminator Loss: 1.1446 Generator Loss: 0.9711\n",
            "Epoch: 522/1000 Discriminator Loss: 1.1726 Generator Loss: 1.1867\n",
            "Epoch: 523/1000 Discriminator Loss: 1.3626 Generator Loss: 1.2973\n",
            "Epoch: 524/1000 Discriminator Loss: 1.2648 Generator Loss: 1.4589\n",
            "Epoch: 525/1000 Discriminator Loss: 1.0412 Generator Loss: 1.1581\n",
            "Epoch: 526/1000 Discriminator Loss: 1.7155 Generator Loss: 1.3387\n",
            "Epoch: 527/1000 Discriminator Loss: 1.5129 Generator Loss: 1.2399\n",
            "Epoch: 528/1000 Discriminator Loss: 1.4388 Generator Loss: 0.7717\n",
            "Epoch: 529/1000 Discriminator Loss: 1.0322 Generator Loss: 1.5205\n",
            "Epoch: 530/1000 Discriminator Loss: 0.7059 Generator Loss: 1.3281\n",
            "Epoch: 531/1000 Discriminator Loss: 1.0012 Generator Loss: 1.1692\n",
            "Epoch: 532/1000 Discriminator Loss: 1.9844 Generator Loss: 1.4904\n",
            "Epoch: 533/1000 Discriminator Loss: 1.5738 Generator Loss: 0.9501\n",
            "Epoch: 534/1000 Discriminator Loss: 1.0591 Generator Loss: 1.7097\n",
            "Epoch: 535/1000 Discriminator Loss: 1.6421 Generator Loss: 0.9689\n",
            "Epoch: 536/1000 Discriminator Loss: 2.4180 Generator Loss: 1.3605\n",
            "Epoch: 537/1000 Discriminator Loss: 1.3753 Generator Loss: 0.8035\n",
            "Epoch: 538/1000 Discriminator Loss: 0.8853 Generator Loss: 1.1403\n",
            "Epoch: 539/1000 Discriminator Loss: 1.2631 Generator Loss: 1.0436\n",
            "Epoch: 540/1000 Discriminator Loss: 1.2114 Generator Loss: 1.4070\n",
            "Epoch: 541/1000 Discriminator Loss: 0.7036 Generator Loss: 1.1782\n",
            "Epoch: 542/1000 Discriminator Loss: 1.5818 Generator Loss: 1.2147\n",
            "Epoch: 543/1000 Discriminator Loss: 1.3868 Generator Loss: 0.8616\n",
            "Epoch: 544/1000 Discriminator Loss: 1.9806 Generator Loss: 1.0748\n",
            "Epoch: 545/1000 Discriminator Loss: 1.3426 Generator Loss: 1.2848\n",
            "Epoch: 546/1000 Discriminator Loss: 1.2492 Generator Loss: 0.8748\n",
            "Epoch: 547/1000 Discriminator Loss: 0.9399 Generator Loss: 1.5049\n",
            "Epoch: 548/1000 Discriminator Loss: 0.7131 Generator Loss: 1.5001\n",
            "Epoch: 549/1000 Discriminator Loss: 1.2655 Generator Loss: 0.9844\n",
            "Epoch: 550/1000 Discriminator Loss: 0.6789 Generator Loss: 1.5798\n",
            "Epoch: 551/1000 Discriminator Loss: 1.2962 Generator Loss: 1.1249\n",
            "Epoch: 552/1000 Discriminator Loss: 0.9786 Generator Loss: 1.0823\n",
            "Epoch: 553/1000 Discriminator Loss: 1.4446 Generator Loss: 0.8015\n",
            "Epoch: 554/1000 Discriminator Loss: 1.3439 Generator Loss: 0.9520\n",
            "Epoch: 555/1000 Discriminator Loss: 1.1171 Generator Loss: 1.1524\n",
            "Epoch: 556/1000 Discriminator Loss: 1.4933 Generator Loss: 0.8331\n",
            "Epoch: 557/1000 Discriminator Loss: 1.1528 Generator Loss: 0.9168\n",
            "Epoch: 558/1000 Discriminator Loss: 1.2327 Generator Loss: 1.0627\n",
            "Epoch: 559/1000 Discriminator Loss: 1.5962 Generator Loss: 0.8335\n",
            "Epoch: 560/1000 Discriminator Loss: 1.2929 Generator Loss: 0.7025\n",
            "Epoch: 561/1000 Discriminator Loss: 1.6547 Generator Loss: 0.9751\n",
            "Epoch: 562/1000 Discriminator Loss: 0.6573 Generator Loss: 1.3922\n",
            "Epoch: 563/1000 Discriminator Loss: 1.0238 Generator Loss: 1.4581\n",
            "Epoch: 564/1000 Discriminator Loss: 0.6679 Generator Loss: 1.4789\n",
            "Epoch: 565/1000 Discriminator Loss: 0.9567 Generator Loss: 1.2849\n",
            "Epoch: 566/1000 Discriminator Loss: 2.0317 Generator Loss: 0.7870\n",
            "Epoch: 567/1000 Discriminator Loss: 1.4741 Generator Loss: 1.0892\n",
            "Epoch: 568/1000 Discriminator Loss: 1.3945 Generator Loss: 0.8761\n",
            "Epoch: 569/1000 Discriminator Loss: 1.3616 Generator Loss: 1.1403\n",
            "Epoch: 570/1000 Discriminator Loss: 1.0962 Generator Loss: 1.4976\n",
            "Epoch: 571/1000 Discriminator Loss: 1.0641 Generator Loss: 1.3407\n",
            "Epoch: 572/1000 Discriminator Loss: 1.3164 Generator Loss: 1.0150\n",
            "Epoch: 573/1000 Discriminator Loss: 0.6870 Generator Loss: 1.7020\n",
            "Epoch: 574/1000 Discriminator Loss: 1.3602 Generator Loss: 0.9520\n",
            "Epoch: 575/1000 Discriminator Loss: 1.6485 Generator Loss: 1.1021\n",
            "Epoch: 576/1000 Discriminator Loss: 1.1936 Generator Loss: 1.1679\n",
            "Epoch: 577/1000 Discriminator Loss: 0.7085 Generator Loss: 1.0572\n",
            "Epoch: 578/1000 Discriminator Loss: 1.3589 Generator Loss: 1.2653\n",
            "Epoch: 579/1000 Discriminator Loss: 1.2309 Generator Loss: 1.1776\n",
            "Epoch: 580/1000 Discriminator Loss: 1.9795 Generator Loss: 0.8854\n",
            "Epoch: 581/1000 Discriminator Loss: 0.7751 Generator Loss: 1.3506\n",
            "Epoch: 582/1000 Discriminator Loss: 1.8135 Generator Loss: 1.0608\n",
            "Epoch: 583/1000 Discriminator Loss: 1.1566 Generator Loss: 0.8795\n",
            "Epoch: 584/1000 Discriminator Loss: 1.7497 Generator Loss: 1.3431\n",
            "Epoch: 585/1000 Discriminator Loss: 1.5543 Generator Loss: 1.1159\n",
            "Epoch: 586/1000 Discriminator Loss: 1.4606 Generator Loss: 1.2135\n",
            "Epoch: 587/1000 Discriminator Loss: 1.7608 Generator Loss: 0.8359\n",
            "Epoch: 588/1000 Discriminator Loss: 0.8152 Generator Loss: 1.3085\n",
            "Epoch: 589/1000 Discriminator Loss: 1.4688 Generator Loss: 0.9511\n",
            "Epoch: 590/1000 Discriminator Loss: 1.2791 Generator Loss: 1.1762\n",
            "Epoch: 591/1000 Discriminator Loss: 1.2245 Generator Loss: 1.2859\n",
            "Epoch: 592/1000 Discriminator Loss: 1.4503 Generator Loss: 0.7963\n",
            "Epoch: 593/1000 Discriminator Loss: 1.0553 Generator Loss: 1.2684\n",
            "Epoch: 594/1000 Discriminator Loss: 1.6232 Generator Loss: 1.1264\n",
            "Epoch: 595/1000 Discriminator Loss: 1.7174 Generator Loss: 0.9615\n",
            "Epoch: 596/1000 Discriminator Loss: 1.6537 Generator Loss: 0.9213\n",
            "Epoch: 597/1000 Discriminator Loss: 0.9880 Generator Loss: 1.2496\n",
            "Epoch: 598/1000 Discriminator Loss: 1.5255 Generator Loss: 0.7422\n",
            "Epoch: 599/1000 Discriminator Loss: 0.8183 Generator Loss: 1.2682\n",
            "Epoch: 600/1000 Discriminator Loss: 1.6269 Generator Loss: 0.8880\n",
            "Epoch: 601/1000 Discriminator Loss: 1.1578 Generator Loss: 0.9555\n",
            "Epoch: 602/1000 Discriminator Loss: 1.3835 Generator Loss: 0.7118\n",
            "Epoch: 603/1000 Discriminator Loss: 1.0735 Generator Loss: 0.9138\n",
            "Epoch: 604/1000 Discriminator Loss: 1.4239 Generator Loss: 1.3472\n",
            "Epoch: 605/1000 Discriminator Loss: 1.0936 Generator Loss: 0.9431\n",
            "Epoch: 606/1000 Discriminator Loss: 1.3269 Generator Loss: 0.8100\n",
            "Epoch: 607/1000 Discriminator Loss: 1.3620 Generator Loss: 0.7492\n",
            "Epoch: 608/1000 Discriminator Loss: 0.9851 Generator Loss: 1.1991\n",
            "Epoch: 609/1000 Discriminator Loss: 1.1951 Generator Loss: 1.0707\n",
            "Epoch: 610/1000 Discriminator Loss: 0.9626 Generator Loss: 1.3894\n",
            "Epoch: 611/1000 Discriminator Loss: 1.4068 Generator Loss: 1.0734\n",
            "Epoch: 612/1000 Discriminator Loss: 1.1155 Generator Loss: 1.1793\n",
            "Epoch: 613/1000 Discriminator Loss: 1.4016 Generator Loss: 0.9250\n",
            "Epoch: 614/1000 Discriminator Loss: 1.3688 Generator Loss: 1.0085\n",
            "Epoch: 615/1000 Discriminator Loss: 1.7054 Generator Loss: 0.7697\n",
            "Epoch: 616/1000 Discriminator Loss: 1.5306 Generator Loss: 1.3237\n",
            "Epoch: 617/1000 Discriminator Loss: 1.3181 Generator Loss: 1.3526\n",
            "Epoch: 618/1000 Discriminator Loss: 1.3653 Generator Loss: 0.9645\n",
            "Epoch: 619/1000 Discriminator Loss: 1.1463 Generator Loss: 0.8576\n",
            "Epoch: 620/1000 Discriminator Loss: 1.8063 Generator Loss: 0.6176\n",
            "Epoch: 621/1000 Discriminator Loss: 1.4314 Generator Loss: 0.9447\n",
            "Epoch: 622/1000 Discriminator Loss: 1.4253 Generator Loss: 0.9663\n",
            "Epoch: 623/1000 Discriminator Loss: 1.0497 Generator Loss: 0.9603\n",
            "Epoch: 624/1000 Discriminator Loss: 1.5791 Generator Loss: 0.9969\n",
            "Epoch: 625/1000 Discriminator Loss: 1.2934 Generator Loss: 0.9423\n",
            "Epoch: 626/1000 Discriminator Loss: 1.1224 Generator Loss: 1.0584\n",
            "Epoch: 627/1000 Discriminator Loss: 1.0612 Generator Loss: 1.4019\n",
            "Epoch: 628/1000 Discriminator Loss: 1.3206 Generator Loss: 0.8332\n",
            "Epoch: 629/1000 Discriminator Loss: 1.8752 Generator Loss: 0.8124\n",
            "Epoch: 630/1000 Discriminator Loss: 1.1216 Generator Loss: 0.9722\n",
            "Epoch: 631/1000 Discriminator Loss: 1.0402 Generator Loss: 1.3182\n",
            "Epoch: 632/1000 Discriminator Loss: 1.7177 Generator Loss: 0.8170\n",
            "Epoch: 633/1000 Discriminator Loss: 1.3971 Generator Loss: 0.7927\n",
            "Epoch: 634/1000 Discriminator Loss: 1.1564 Generator Loss: 0.9705\n",
            "Epoch: 635/1000 Discriminator Loss: 1.2355 Generator Loss: 1.3062\n",
            "Epoch: 636/1000 Discriminator Loss: 1.6174 Generator Loss: 0.7531\n",
            "Epoch: 637/1000 Discriminator Loss: 1.2164 Generator Loss: 0.9498\n",
            "Epoch: 638/1000 Discriminator Loss: 1.8745 Generator Loss: 0.9397\n",
            "Epoch: 639/1000 Discriminator Loss: 1.9386 Generator Loss: 0.9146\n",
            "Epoch: 640/1000 Discriminator Loss: 1.6319 Generator Loss: 1.0417\n",
            "Epoch: 641/1000 Discriminator Loss: 1.1847 Generator Loss: 1.0140\n",
            "Epoch: 642/1000 Discriminator Loss: 1.0630 Generator Loss: 1.2623\n",
            "Epoch: 643/1000 Discriminator Loss: 1.2351 Generator Loss: 1.0026\n",
            "Epoch: 644/1000 Discriminator Loss: 1.6257 Generator Loss: 0.9808\n",
            "Epoch: 645/1000 Discriminator Loss: 1.0922 Generator Loss: 0.9969\n",
            "Epoch: 646/1000 Discriminator Loss: 1.3904 Generator Loss: 1.0505\n",
            "Epoch: 647/1000 Discriminator Loss: 1.5308 Generator Loss: 0.7376\n",
            "Epoch: 648/1000 Discriminator Loss: 0.7158 Generator Loss: 1.5393\n",
            "Epoch: 649/1000 Discriminator Loss: 1.4918 Generator Loss: 1.1862\n",
            "Epoch: 650/1000 Discriminator Loss: 1.4525 Generator Loss: 0.9967\n",
            "Epoch: 651/1000 Discriminator Loss: 1.0656 Generator Loss: 1.1448\n",
            "Epoch: 652/1000 Discriminator Loss: 1.4356 Generator Loss: 1.4649\n",
            "Epoch: 653/1000 Discriminator Loss: 1.1124 Generator Loss: 1.1258\n",
            "Epoch: 654/1000 Discriminator Loss: 0.7532 Generator Loss: 1.2183\n",
            "Epoch: 655/1000 Discriminator Loss: 0.6565 Generator Loss: 1.5439\n",
            "Epoch: 656/1000 Discriminator Loss: 0.8554 Generator Loss: 1.3020\n",
            "Epoch: 657/1000 Discriminator Loss: 1.1253 Generator Loss: 1.0824\n",
            "Epoch: 658/1000 Discriminator Loss: 1.2499 Generator Loss: 0.9975\n",
            "Epoch: 659/1000 Discriminator Loss: 1.2663 Generator Loss: 1.1156\n",
            "Epoch: 660/1000 Discriminator Loss: 1.4909 Generator Loss: 0.9262\n",
            "Epoch: 661/1000 Discriminator Loss: 1.0093 Generator Loss: 1.2450\n",
            "Epoch: 662/1000 Discriminator Loss: 0.8961 Generator Loss: 1.1461\n",
            "Epoch: 663/1000 Discriminator Loss: 1.3808 Generator Loss: 0.7939\n",
            "Epoch: 664/1000 Discriminator Loss: 1.3306 Generator Loss: 0.8201\n",
            "Epoch: 665/1000 Discriminator Loss: 1.2503 Generator Loss: 1.0975\n",
            "Epoch: 666/1000 Discriminator Loss: 1.3145 Generator Loss: 1.0617\n",
            "Epoch: 667/1000 Discriminator Loss: 0.9203 Generator Loss: 1.2886\n",
            "Epoch: 668/1000 Discriminator Loss: 0.9192 Generator Loss: 0.8313\n",
            "Epoch: 669/1000 Discriminator Loss: 0.8795 Generator Loss: 1.3712\n",
            "Epoch: 670/1000 Discriminator Loss: 1.4335 Generator Loss: 0.9569\n",
            "Epoch: 671/1000 Discriminator Loss: 1.0430 Generator Loss: 1.0977\n",
            "Epoch: 672/1000 Discriminator Loss: 1.2705 Generator Loss: 1.1369\n",
            "Epoch: 673/1000 Discriminator Loss: 1.4250 Generator Loss: 0.9173\n",
            "Epoch: 674/1000 Discriminator Loss: 1.4043 Generator Loss: 0.6624\n",
            "Epoch: 675/1000 Discriminator Loss: 1.4794 Generator Loss: 1.1273\n",
            "Epoch: 676/1000 Discriminator Loss: 0.6358 Generator Loss: 1.4978\n",
            "Epoch: 677/1000 Discriminator Loss: 1.2260 Generator Loss: 1.5215\n",
            "Epoch: 678/1000 Discriminator Loss: 1.3448 Generator Loss: 1.1502\n",
            "Epoch: 679/1000 Discriminator Loss: 1.1270 Generator Loss: 1.4030\n",
            "Epoch: 680/1000 Discriminator Loss: 0.6197 Generator Loss: 1.6745\n",
            "Epoch: 681/1000 Discriminator Loss: 1.1550 Generator Loss: 1.0058\n",
            "Epoch: 682/1000 Discriminator Loss: 1.5658 Generator Loss: 0.9890\n",
            "Epoch: 683/1000 Discriminator Loss: 1.2713 Generator Loss: 1.0502\n",
            "Epoch: 684/1000 Discriminator Loss: 1.3200 Generator Loss: 1.0823\n",
            "Epoch: 685/1000 Discriminator Loss: 0.7349 Generator Loss: 1.2142\n",
            "Epoch: 686/1000 Discriminator Loss: 1.3007 Generator Loss: 0.9617\n",
            "Epoch: 687/1000 Discriminator Loss: 1.0938 Generator Loss: 1.3067\n",
            "Epoch: 688/1000 Discriminator Loss: 1.2536 Generator Loss: 1.1938\n",
            "Epoch: 689/1000 Discriminator Loss: 1.1996 Generator Loss: 1.1363\n",
            "Epoch: 690/1000 Discriminator Loss: 1.3061 Generator Loss: 1.1941\n",
            "Epoch: 691/1000 Discriminator Loss: 1.1424 Generator Loss: 1.2584\n",
            "Epoch: 692/1000 Discriminator Loss: 1.4133 Generator Loss: 0.9300\n",
            "Epoch: 693/1000 Discriminator Loss: 1.2300 Generator Loss: 1.3918\n",
            "Epoch: 694/1000 Discriminator Loss: 1.2893 Generator Loss: 1.1884\n",
            "Epoch: 695/1000 Discriminator Loss: 1.2153 Generator Loss: 1.1079\n",
            "Epoch: 696/1000 Discriminator Loss: 1.1171 Generator Loss: 1.0798\n",
            "Epoch: 697/1000 Discriminator Loss: 1.2647 Generator Loss: 1.2783\n",
            "Epoch: 698/1000 Discriminator Loss: 0.8585 Generator Loss: 1.4090\n",
            "Epoch: 699/1000 Discriminator Loss: 0.6369 Generator Loss: 1.4563\n",
            "Epoch: 700/1000 Discriminator Loss: 0.8935 Generator Loss: 1.2700\n",
            "Epoch: 701/1000 Discriminator Loss: 1.5038 Generator Loss: 0.8626\n",
            "Epoch: 702/1000 Discriminator Loss: 1.0181 Generator Loss: 1.2050\n",
            "Epoch: 703/1000 Discriminator Loss: 1.4355 Generator Loss: 1.1905\n",
            "Epoch: 704/1000 Discriminator Loss: 0.5637 Generator Loss: 1.8268\n",
            "Epoch: 705/1000 Discriminator Loss: 1.5592 Generator Loss: 0.8541\n",
            "Epoch: 706/1000 Discriminator Loss: 1.0489 Generator Loss: 1.0261\n",
            "Epoch: 707/1000 Discriminator Loss: 1.3375 Generator Loss: 1.0545\n",
            "Epoch: 708/1000 Discriminator Loss: 1.3490 Generator Loss: 1.1826\n",
            "Epoch: 709/1000 Discriminator Loss: 1.0653 Generator Loss: 1.2512\n",
            "Epoch: 710/1000 Discriminator Loss: 0.9906 Generator Loss: 1.5018\n",
            "Epoch: 711/1000 Discriminator Loss: 1.2767 Generator Loss: 1.4965\n",
            "Epoch: 712/1000 Discriminator Loss: 0.9145 Generator Loss: 1.1326\n",
            "Epoch: 713/1000 Discriminator Loss: 0.6628 Generator Loss: 1.2942\n",
            "Epoch: 714/1000 Discriminator Loss: 1.2333 Generator Loss: 1.2026\n",
            "Epoch: 715/1000 Discriminator Loss: 1.1133 Generator Loss: 1.2208\n",
            "Epoch: 716/1000 Discriminator Loss: 0.9987 Generator Loss: 1.1398\n",
            "Epoch: 717/1000 Discriminator Loss: 0.6333 Generator Loss: 1.4025\n",
            "Epoch: 718/1000 Discriminator Loss: 1.6269 Generator Loss: 0.8843\n",
            "Epoch: 719/1000 Discriminator Loss: 1.4121 Generator Loss: 1.2929\n",
            "Epoch: 720/1000 Discriminator Loss: 1.4442 Generator Loss: 0.8578\n",
            "Epoch: 721/1000 Discriminator Loss: 1.6426 Generator Loss: 0.9110\n",
            "Epoch: 722/1000 Discriminator Loss: 1.3662 Generator Loss: 0.8915\n",
            "Epoch: 723/1000 Discriminator Loss: 0.8949 Generator Loss: 1.5450\n",
            "Epoch: 724/1000 Discriminator Loss: 1.5157 Generator Loss: 0.9379\n",
            "Epoch: 725/1000 Discriminator Loss: 1.4400 Generator Loss: 1.3014\n",
            "Epoch: 726/1000 Discriminator Loss: 0.9428 Generator Loss: 1.4793\n",
            "Epoch: 727/1000 Discriminator Loss: 1.5577 Generator Loss: 1.0738\n",
            "Epoch: 728/1000 Discriminator Loss: 1.3612 Generator Loss: 1.1334\n",
            "Epoch: 729/1000 Discriminator Loss: 1.4041 Generator Loss: 1.1935\n",
            "Epoch: 730/1000 Discriminator Loss: 1.3730 Generator Loss: 0.9117\n",
            "Epoch: 731/1000 Discriminator Loss: 1.4132 Generator Loss: 0.9332\n",
            "Epoch: 732/1000 Discriminator Loss: 1.5081 Generator Loss: 0.9282\n",
            "Epoch: 733/1000 Discriminator Loss: 1.4952 Generator Loss: 0.8021\n",
            "Epoch: 734/1000 Discriminator Loss: 0.9466 Generator Loss: 1.0882\n",
            "Epoch: 735/1000 Discriminator Loss: 1.7660 Generator Loss: 0.7962\n",
            "Epoch: 736/1000 Discriminator Loss: 1.1972 Generator Loss: 1.1643\n",
            "Epoch: 737/1000 Discriminator Loss: 1.0365 Generator Loss: 1.3924\n",
            "Epoch: 738/1000 Discriminator Loss: 1.1386 Generator Loss: 1.1029\n",
            "Epoch: 739/1000 Discriminator Loss: 1.0036 Generator Loss: 1.2747\n",
            "Epoch: 740/1000 Discriminator Loss: 1.3598 Generator Loss: 0.9308\n",
            "Epoch: 741/1000 Discriminator Loss: 1.7291 Generator Loss: 0.9991\n",
            "Epoch: 742/1000 Discriminator Loss: 1.5574 Generator Loss: 0.9528\n",
            "Epoch: 743/1000 Discriminator Loss: 1.3228 Generator Loss: 0.9266\n",
            "Epoch: 744/1000 Discriminator Loss: 0.9470 Generator Loss: 1.2188\n",
            "Epoch: 745/1000 Discriminator Loss: 1.9553 Generator Loss: 0.7005\n",
            "Epoch: 746/1000 Discriminator Loss: 1.3283 Generator Loss: 0.8917\n",
            "Epoch: 747/1000 Discriminator Loss: 1.0699 Generator Loss: 1.2977\n",
            "Epoch: 748/1000 Discriminator Loss: 0.5516 Generator Loss: 1.5023\n",
            "Epoch: 749/1000 Discriminator Loss: 1.4021 Generator Loss: 1.0126\n",
            "Epoch: 750/1000 Discriminator Loss: 1.4526 Generator Loss: 0.7958\n",
            "Epoch: 751/1000 Discriminator Loss: 0.9375 Generator Loss: 1.2614\n",
            "Epoch: 752/1000 Discriminator Loss: 1.3573 Generator Loss: 0.9661\n",
            "Epoch: 753/1000 Discriminator Loss: 1.0065 Generator Loss: 1.5104\n",
            "Epoch: 754/1000 Discriminator Loss: 1.5609 Generator Loss: 1.0124\n",
            "Epoch: 755/1000 Discriminator Loss: 1.2104 Generator Loss: 1.0822\n",
            "Epoch: 756/1000 Discriminator Loss: 1.2274 Generator Loss: 1.1812\n",
            "Epoch: 757/1000 Discriminator Loss: 1.8048 Generator Loss: 0.8914\n",
            "Epoch: 758/1000 Discriminator Loss: 1.4548 Generator Loss: 0.9932\n",
            "Epoch: 759/1000 Discriminator Loss: 1.4395 Generator Loss: 1.0636\n",
            "Epoch: 760/1000 Discriminator Loss: 1.1726 Generator Loss: 1.2967\n",
            "Epoch: 761/1000 Discriminator Loss: 0.9707 Generator Loss: 0.9688\n",
            "Epoch: 762/1000 Discriminator Loss: 1.3734 Generator Loss: 1.1623\n",
            "Epoch: 763/1000 Discriminator Loss: 1.6574 Generator Loss: 0.7806\n",
            "Epoch: 764/1000 Discriminator Loss: 1.1719 Generator Loss: 1.1155\n",
            "Epoch: 765/1000 Discriminator Loss: 1.3419 Generator Loss: 0.7691\n",
            "Epoch: 766/1000 Discriminator Loss: 1.0501 Generator Loss: 1.1170\n",
            "Epoch: 767/1000 Discriminator Loss: 1.6638 Generator Loss: 0.8036\n",
            "Epoch: 768/1000 Discriminator Loss: 1.2449 Generator Loss: 0.8898\n",
            "Epoch: 769/1000 Discriminator Loss: 1.8392 Generator Loss: 1.0134\n",
            "Epoch: 770/1000 Discriminator Loss: 1.3214 Generator Loss: 0.9108\n",
            "Epoch: 771/1000 Discriminator Loss: 1.4564 Generator Loss: 1.2940\n",
            "Epoch: 772/1000 Discriminator Loss: 1.4940 Generator Loss: 1.2248\n",
            "Epoch: 773/1000 Discriminator Loss: 1.3999 Generator Loss: 1.0651\n",
            "Epoch: 774/1000 Discriminator Loss: 1.3442 Generator Loss: 0.9690\n",
            "Epoch: 775/1000 Discriminator Loss: 1.0153 Generator Loss: 1.1613\n",
            "Epoch: 776/1000 Discriminator Loss: 1.0390 Generator Loss: 0.9235\n",
            "Epoch: 777/1000 Discriminator Loss: 1.3402 Generator Loss: 0.9726\n",
            "Epoch: 778/1000 Discriminator Loss: 1.5570 Generator Loss: 0.8963\n",
            "Epoch: 779/1000 Discriminator Loss: 1.2184 Generator Loss: 1.0050\n",
            "Epoch: 780/1000 Discriminator Loss: 1.4892 Generator Loss: 1.0239\n",
            "Epoch: 781/1000 Discriminator Loss: 1.4188 Generator Loss: 0.9321\n",
            "Epoch: 782/1000 Discriminator Loss: 1.4343 Generator Loss: 0.9894\n",
            "Epoch: 783/1000 Discriminator Loss: 1.2386 Generator Loss: 0.9505\n",
            "Epoch: 784/1000 Discriminator Loss: 1.2470 Generator Loss: 1.1440\n",
            "Epoch: 785/1000 Discriminator Loss: 1.0330 Generator Loss: 1.2798\n",
            "Epoch: 786/1000 Discriminator Loss: 1.0516 Generator Loss: 1.2385\n",
            "Epoch: 787/1000 Discriminator Loss: 0.9789 Generator Loss: 0.9861\n",
            "Epoch: 788/1000 Discriminator Loss: 1.2968 Generator Loss: 0.7896\n",
            "Epoch: 789/1000 Discriminator Loss: 1.1256 Generator Loss: 0.9394\n",
            "Epoch: 790/1000 Discriminator Loss: 1.1505 Generator Loss: 1.0449\n",
            "Epoch: 791/1000 Discriminator Loss: 1.1744 Generator Loss: 0.8971\n",
            "Epoch: 792/1000 Discriminator Loss: 1.3941 Generator Loss: 0.8221\n",
            "Epoch: 793/1000 Discriminator Loss: 1.2995 Generator Loss: 0.9096\n",
            "Epoch: 794/1000 Discriminator Loss: 1.1360 Generator Loss: 1.2269\n",
            "Epoch: 795/1000 Discriminator Loss: 1.3072 Generator Loss: 0.7669\n",
            "Epoch: 796/1000 Discriminator Loss: 1.4298 Generator Loss: 0.9548\n",
            "Epoch: 797/1000 Discriminator Loss: 1.3228 Generator Loss: 0.9038\n",
            "Epoch: 798/1000 Discriminator Loss: 1.5416 Generator Loss: 1.1920\n",
            "Epoch: 799/1000 Discriminator Loss: 1.6091 Generator Loss: 0.7523\n",
            "Epoch: 800/1000 Discriminator Loss: 1.3423 Generator Loss: 0.9691\n",
            "Epoch: 801/1000 Discriminator Loss: 0.7445 Generator Loss: 1.2408\n",
            "Epoch: 802/1000 Discriminator Loss: 1.1434 Generator Loss: 1.1241\n",
            "Epoch: 803/1000 Discriminator Loss: 1.1412 Generator Loss: 1.0354\n",
            "Epoch: 804/1000 Discriminator Loss: 1.2848 Generator Loss: 1.3381\n",
            "Epoch: 805/1000 Discriminator Loss: 1.2798 Generator Loss: 0.9214\n",
            "Epoch: 806/1000 Discriminator Loss: 1.4557 Generator Loss: 0.9746\n",
            "Epoch: 807/1000 Discriminator Loss: 1.0888 Generator Loss: 1.2276\n",
            "Epoch: 808/1000 Discriminator Loss: 1.3292 Generator Loss: 0.9928\n",
            "Epoch: 809/1000 Discriminator Loss: 0.8089 Generator Loss: 1.2790\n",
            "Epoch: 810/1000 Discriminator Loss: 1.1503 Generator Loss: 1.0337\n",
            "Epoch: 811/1000 Discriminator Loss: 1.4277 Generator Loss: 0.9047\n",
            "Epoch: 812/1000 Discriminator Loss: 1.4439 Generator Loss: 0.7113\n",
            "Epoch: 813/1000 Discriminator Loss: 1.2115 Generator Loss: 0.9780\n",
            "Epoch: 814/1000 Discriminator Loss: 1.3035 Generator Loss: 0.9430\n",
            "Epoch: 815/1000 Discriminator Loss: 1.3286 Generator Loss: 0.7810\n",
            "Epoch: 816/1000 Discriminator Loss: 1.5573 Generator Loss: 1.0170\n",
            "Epoch: 817/1000 Discriminator Loss: 1.2712 Generator Loss: 1.0016\n",
            "Epoch: 818/1000 Discriminator Loss: 1.3106 Generator Loss: 0.9765\n",
            "Epoch: 819/1000 Discriminator Loss: 1.2041 Generator Loss: 1.1677\n",
            "Epoch: 820/1000 Discriminator Loss: 1.5030 Generator Loss: 1.0020\n",
            "Epoch: 821/1000 Discriminator Loss: 1.3908 Generator Loss: 0.8817\n",
            "Epoch: 822/1000 Discriminator Loss: 1.2290 Generator Loss: 0.8574\n",
            "Epoch: 823/1000 Discriminator Loss: 1.2101 Generator Loss: 1.1134\n",
            "Epoch: 824/1000 Discriminator Loss: 1.3675 Generator Loss: 1.1998\n",
            "Epoch: 825/1000 Discriminator Loss: 1.2696 Generator Loss: 1.0364\n",
            "Epoch: 826/1000 Discriminator Loss: 1.3683 Generator Loss: 1.0164\n",
            "Epoch: 827/1000 Discriminator Loss: 1.5142 Generator Loss: 1.1429\n",
            "Epoch: 828/1000 Discriminator Loss: 1.9181 Generator Loss: 0.8874\n",
            "Epoch: 829/1000 Discriminator Loss: 0.9016 Generator Loss: 1.2619\n",
            "Epoch: 830/1000 Discriminator Loss: 1.5202 Generator Loss: 1.0592\n",
            "Epoch: 831/1000 Discriminator Loss: 1.4423 Generator Loss: 0.9065\n",
            "Epoch: 832/1000 Discriminator Loss: 1.6251 Generator Loss: 1.0443\n",
            "Epoch: 833/1000 Discriminator Loss: 1.3755 Generator Loss: 0.8209\n",
            "Epoch: 834/1000 Discriminator Loss: 1.3406 Generator Loss: 0.7725\n",
            "Epoch: 835/1000 Discriminator Loss: 1.3614 Generator Loss: 1.0018\n",
            "Epoch: 836/1000 Discriminator Loss: 1.1178 Generator Loss: 1.0960\n",
            "Epoch: 837/1000 Discriminator Loss: 1.5797 Generator Loss: 0.9392\n",
            "Epoch: 838/1000 Discriminator Loss: 1.3464 Generator Loss: 1.1591\n",
            "Epoch: 839/1000 Discriminator Loss: 1.9084 Generator Loss: 0.7588\n",
            "Epoch: 840/1000 Discriminator Loss: 1.4365 Generator Loss: 0.6994\n",
            "Epoch: 841/1000 Discriminator Loss: 1.4952 Generator Loss: 1.0452\n",
            "Epoch: 842/1000 Discriminator Loss: 1.1809 Generator Loss: 0.7779\n",
            "Epoch: 843/1000 Discriminator Loss: 1.6278 Generator Loss: 1.2102\n",
            "Epoch: 844/1000 Discriminator Loss: 1.1065 Generator Loss: 0.7799\n",
            "Epoch: 845/1000 Discriminator Loss: 1.4887 Generator Loss: 0.9598\n",
            "Epoch: 846/1000 Discriminator Loss: 1.4954 Generator Loss: 0.9049\n",
            "Epoch: 847/1000 Discriminator Loss: 1.4004 Generator Loss: 0.9771\n",
            "Epoch: 848/1000 Discriminator Loss: 1.3210 Generator Loss: 0.7193\n",
            "Epoch: 849/1000 Discriminator Loss: 1.4053 Generator Loss: 0.8464\n",
            "Epoch: 850/1000 Discriminator Loss: 1.4136 Generator Loss: 0.8559\n",
            "Epoch: 851/1000 Discriminator Loss: 1.0990 Generator Loss: 1.0437\n",
            "Epoch: 852/1000 Discriminator Loss: 1.4157 Generator Loss: 1.1296\n",
            "Epoch: 853/1000 Discriminator Loss: 1.3694 Generator Loss: 1.0792\n",
            "Epoch: 854/1000 Discriminator Loss: 1.2939 Generator Loss: 0.8177\n",
            "Epoch: 855/1000 Discriminator Loss: 1.4652 Generator Loss: 1.0257\n",
            "Epoch: 856/1000 Discriminator Loss: 1.1230 Generator Loss: 1.0036\n",
            "Epoch: 857/1000 Discriminator Loss: 1.5386 Generator Loss: 1.0349\n",
            "Epoch: 858/1000 Discriminator Loss: 1.8103 Generator Loss: 0.7064\n",
            "Epoch: 859/1000 Discriminator Loss: 1.7310 Generator Loss: 0.7131\n",
            "Epoch: 860/1000 Discriminator Loss: 1.2281 Generator Loss: 1.0069\n",
            "Epoch: 861/1000 Discriminator Loss: 1.2351 Generator Loss: 0.8497\n",
            "Epoch: 862/1000 Discriminator Loss: 1.3011 Generator Loss: 0.8281\n",
            "Epoch: 863/1000 Discriminator Loss: 1.2923 Generator Loss: 0.8854\n",
            "Epoch: 864/1000 Discriminator Loss: 1.5594 Generator Loss: 0.7007\n",
            "Epoch: 865/1000 Discriminator Loss: 1.2098 Generator Loss: 0.8085\n",
            "Epoch: 866/1000 Discriminator Loss: 1.7125 Generator Loss: 0.8769\n",
            "Epoch: 867/1000 Discriminator Loss: 1.5566 Generator Loss: 0.7631\n",
            "Epoch: 868/1000 Discriminator Loss: 1.3210 Generator Loss: 1.0760\n",
            "Epoch: 869/1000 Discriminator Loss: 1.3471 Generator Loss: 0.9564\n",
            "Epoch: 870/1000 Discriminator Loss: 1.6557 Generator Loss: 0.8226\n",
            "Epoch: 871/1000 Discriminator Loss: 0.9376 Generator Loss: 1.1468\n",
            "Epoch: 872/1000 Discriminator Loss: 1.4300 Generator Loss: 0.8262\n",
            "Epoch: 873/1000 Discriminator Loss: 1.3218 Generator Loss: 0.7556\n",
            "Epoch: 874/1000 Discriminator Loss: 0.8549 Generator Loss: 1.4647\n",
            "Epoch: 875/1000 Discriminator Loss: 1.2495 Generator Loss: 0.9527\n",
            "Epoch: 876/1000 Discriminator Loss: 1.0832 Generator Loss: 1.0507\n",
            "Epoch: 877/1000 Discriminator Loss: 1.5765 Generator Loss: 0.9917\n",
            "Epoch: 878/1000 Discriminator Loss: 1.2787 Generator Loss: 1.0484\n",
            "Epoch: 879/1000 Discriminator Loss: 1.0984 Generator Loss: 1.0154\n",
            "Epoch: 880/1000 Discriminator Loss: 1.2262 Generator Loss: 0.9858\n",
            "Epoch: 881/1000 Discriminator Loss: 0.9632 Generator Loss: 0.9394\n",
            "Epoch: 882/1000 Discriminator Loss: 1.4832 Generator Loss: 0.8400\n",
            "Epoch: 883/1000 Discriminator Loss: 1.5827 Generator Loss: 0.7886\n",
            "Epoch: 884/1000 Discriminator Loss: 1.5069 Generator Loss: 0.9918\n",
            "Epoch: 885/1000 Discriminator Loss: 1.6566 Generator Loss: 0.8690\n",
            "Epoch: 886/1000 Discriminator Loss: 1.2502 Generator Loss: 0.9733\n",
            "Epoch: 887/1000 Discriminator Loss: 1.4048 Generator Loss: 0.7327\n",
            "Epoch: 888/1000 Discriminator Loss: 1.2049 Generator Loss: 0.7875\n",
            "Epoch: 889/1000 Discriminator Loss: 1.0495 Generator Loss: 1.0634\n",
            "Epoch: 890/1000 Discriminator Loss: 1.3531 Generator Loss: 1.0506\n",
            "Epoch: 891/1000 Discriminator Loss: 1.3986 Generator Loss: 0.8311\n",
            "Epoch: 892/1000 Discriminator Loss: 1.1510 Generator Loss: 1.0323\n",
            "Epoch: 893/1000 Discriminator Loss: 1.1671 Generator Loss: 1.3226\n",
            "Epoch: 894/1000 Discriminator Loss: 0.7608 Generator Loss: 1.3027\n",
            "Epoch: 895/1000 Discriminator Loss: 1.3952 Generator Loss: 0.8358\n",
            "Epoch: 896/1000 Discriminator Loss: 1.5467 Generator Loss: 1.1557\n",
            "Epoch: 897/1000 Discriminator Loss: 1.5182 Generator Loss: 0.9655\n",
            "Epoch: 898/1000 Discriminator Loss: 1.3525 Generator Loss: 0.9627\n",
            "Epoch: 899/1000 Discriminator Loss: 1.4310 Generator Loss: 0.8927\n",
            "Epoch: 900/1000 Discriminator Loss: 1.4548 Generator Loss: 0.9409\n",
            "Epoch: 901/1000 Discriminator Loss: 1.2529 Generator Loss: 0.7960\n",
            "Epoch: 902/1000 Discriminator Loss: 1.3308 Generator Loss: 0.9898\n",
            "Epoch: 903/1000 Discriminator Loss: 1.5115 Generator Loss: 0.7255\n",
            "Epoch: 904/1000 Discriminator Loss: 1.6068 Generator Loss: 0.8047\n",
            "Epoch: 905/1000 Discriminator Loss: 1.6334 Generator Loss: 0.7466\n",
            "Epoch: 906/1000 Discriminator Loss: 1.4926 Generator Loss: 0.8446\n",
            "Epoch: 907/1000 Discriminator Loss: 1.3771 Generator Loss: 1.1701\n",
            "Epoch: 908/1000 Discriminator Loss: 1.6272 Generator Loss: 0.6472\n",
            "Epoch: 909/1000 Discriminator Loss: 1.4255 Generator Loss: 0.8037\n",
            "Epoch: 910/1000 Discriminator Loss: 1.2839 Generator Loss: 0.7924\n",
            "Epoch: 911/1000 Discriminator Loss: 1.2823 Generator Loss: 1.1340\n",
            "Epoch: 912/1000 Discriminator Loss: 1.1956 Generator Loss: 0.9312\n",
            "Epoch: 913/1000 Discriminator Loss: 1.3211 Generator Loss: 1.2147\n",
            "Epoch: 914/1000 Discriminator Loss: 1.7428 Generator Loss: 0.9064\n",
            "Epoch: 915/1000 Discriminator Loss: 1.1632 Generator Loss: 0.8993\n",
            "Epoch: 916/1000 Discriminator Loss: 1.1276 Generator Loss: 1.0174\n",
            "Epoch: 917/1000 Discriminator Loss: 1.6264 Generator Loss: 0.9974\n",
            "Epoch: 918/1000 Discriminator Loss: 1.5427 Generator Loss: 0.6714\n",
            "Epoch: 919/1000 Discriminator Loss: 1.2566 Generator Loss: 0.8685\n",
            "Epoch: 920/1000 Discriminator Loss: 1.2739 Generator Loss: 0.8409\n",
            "Epoch: 921/1000 Discriminator Loss: 1.4319 Generator Loss: 0.9853\n",
            "Epoch: 922/1000 Discriminator Loss: 1.6357 Generator Loss: 0.9338\n",
            "Epoch: 923/1000 Discriminator Loss: 0.9575 Generator Loss: 0.9050\n",
            "Epoch: 924/1000 Discriminator Loss: 1.7322 Generator Loss: 0.7206\n",
            "Epoch: 925/1000 Discriminator Loss: 1.5915 Generator Loss: 0.9882\n",
            "Epoch: 926/1000 Discriminator Loss: 1.6652 Generator Loss: 1.0736\n",
            "Epoch: 927/1000 Discriminator Loss: 1.2868 Generator Loss: 0.7968\n",
            "Epoch: 928/1000 Discriminator Loss: 1.4070 Generator Loss: 0.9173\n",
            "Epoch: 929/1000 Discriminator Loss: 1.2988 Generator Loss: 0.8989\n",
            "Epoch: 930/1000 Discriminator Loss: 1.1688 Generator Loss: 0.9535\n",
            "Epoch: 931/1000 Discriminator Loss: 1.2959 Generator Loss: 0.8726\n",
            "Epoch: 932/1000 Discriminator Loss: 1.3519 Generator Loss: 1.0202\n",
            "Epoch: 933/1000 Discriminator Loss: 1.2182 Generator Loss: 1.0266\n",
            "Epoch: 934/1000 Discriminator Loss: 1.3727 Generator Loss: 0.8284\n",
            "Epoch: 935/1000 Discriminator Loss: 1.3745 Generator Loss: 0.8906\n",
            "Epoch: 936/1000 Discriminator Loss: 1.2332 Generator Loss: 0.9944\n",
            "Epoch: 937/1000 Discriminator Loss: 1.4907 Generator Loss: 0.8598\n",
            "Epoch: 938/1000 Discriminator Loss: 1.5507 Generator Loss: 0.8171\n",
            "Epoch: 939/1000 Discriminator Loss: 1.3596 Generator Loss: 0.9146\n",
            "Epoch: 940/1000 Discriminator Loss: 1.2745 Generator Loss: 0.9017\n",
            "Epoch: 941/1000 Discriminator Loss: 1.3046 Generator Loss: 0.7533\n",
            "Epoch: 942/1000 Discriminator Loss: 1.6126 Generator Loss: 0.7083\n",
            "Epoch: 943/1000 Discriminator Loss: 1.6802 Generator Loss: 0.8650\n",
            "Epoch: 944/1000 Discriminator Loss: 1.0837 Generator Loss: 0.9335\n",
            "Epoch: 945/1000 Discriminator Loss: 1.6085 Generator Loss: 0.8169\n",
            "Epoch: 946/1000 Discriminator Loss: 1.3346 Generator Loss: 0.8035\n",
            "Epoch: 947/1000 Discriminator Loss: 1.4108 Generator Loss: 0.9842\n",
            "Epoch: 948/1000 Discriminator Loss: 1.6285 Generator Loss: 0.8965\n",
            "Epoch: 949/1000 Discriminator Loss: 1.5644 Generator Loss: 1.1966\n",
            "Epoch: 950/1000 Discriminator Loss: 1.2147 Generator Loss: 0.8439\n",
            "Epoch: 951/1000 Discriminator Loss: 1.4588 Generator Loss: 0.8508\n",
            "Epoch: 952/1000 Discriminator Loss: 1.3292 Generator Loss: 1.0425\n",
            "Epoch: 953/1000 Discriminator Loss: 1.2002 Generator Loss: 1.0042\n",
            "Epoch: 954/1000 Discriminator Loss: 1.4558 Generator Loss: 0.8595\n",
            "Epoch: 955/1000 Discriminator Loss: 1.4782 Generator Loss: 0.7961\n",
            "Epoch: 956/1000 Discriminator Loss: 1.3661 Generator Loss: 0.8526\n",
            "Epoch: 957/1000 Discriminator Loss: 1.3744 Generator Loss: 0.9669\n",
            "Epoch: 958/1000 Discriminator Loss: 1.4794 Generator Loss: 0.8868\n",
            "Epoch: 959/1000 Discriminator Loss: 1.3092 Generator Loss: 0.9242\n",
            "Epoch: 960/1000 Discriminator Loss: 1.3309 Generator Loss: 1.0325\n",
            "Epoch: 961/1000 Discriminator Loss: 1.1686 Generator Loss: 0.9410\n",
            "Epoch: 962/1000 Discriminator Loss: 1.0796 Generator Loss: 1.2493\n",
            "Epoch: 963/1000 Discriminator Loss: 1.4605 Generator Loss: 0.8694\n",
            "Epoch: 964/1000 Discriminator Loss: 1.0125 Generator Loss: 1.1393\n",
            "Epoch: 965/1000 Discriminator Loss: 1.8815 Generator Loss: 0.7290\n",
            "Epoch: 966/1000 Discriminator Loss: 1.5594 Generator Loss: 0.7077\n",
            "Epoch: 967/1000 Discriminator Loss: 1.4540 Generator Loss: 0.8973\n",
            "Epoch: 968/1000 Discriminator Loss: 1.3410 Generator Loss: 0.8245\n",
            "Epoch: 969/1000 Discriminator Loss: 1.4168 Generator Loss: 0.9411\n",
            "Epoch: 970/1000 Discriminator Loss: 1.2983 Generator Loss: 1.1551\n",
            "Epoch: 971/1000 Discriminator Loss: 1.3133 Generator Loss: 0.8360\n",
            "Epoch: 972/1000 Discriminator Loss: 1.5003 Generator Loss: 0.9720\n",
            "Epoch: 973/1000 Discriminator Loss: 1.6838 Generator Loss: 0.7209\n",
            "Epoch: 974/1000 Discriminator Loss: 1.3468 Generator Loss: 0.9045\n",
            "Epoch: 975/1000 Discriminator Loss: 1.2931 Generator Loss: 0.8702\n",
            "Epoch: 976/1000 Discriminator Loss: 1.3417 Generator Loss: 0.6645\n",
            "Epoch: 977/1000 Discriminator Loss: 1.3657 Generator Loss: 0.8894\n",
            "Epoch: 978/1000 Discriminator Loss: 1.1266 Generator Loss: 0.9535\n",
            "Epoch: 979/1000 Discriminator Loss: 1.1265 Generator Loss: 0.9982\n",
            "Epoch: 980/1000 Discriminator Loss: 1.4339 Generator Loss: 1.0104\n",
            "Epoch: 981/1000 Discriminator Loss: 1.3239 Generator Loss: 0.7671\n",
            "Epoch: 982/1000 Discriminator Loss: 1.1997 Generator Loss: 0.8607\n",
            "Epoch: 983/1000 Discriminator Loss: 1.3756 Generator Loss: 0.7531\n",
            "Epoch: 984/1000 Discriminator Loss: 1.3821 Generator Loss: 0.9529\n",
            "Epoch: 985/1000 Discriminator Loss: 1.4444 Generator Loss: 0.7599\n",
            "Epoch: 986/1000 Discriminator Loss: 1.3674 Generator Loss: 0.9710\n",
            "Epoch: 987/1000 Discriminator Loss: 1.3433 Generator Loss: 0.9654\n",
            "Epoch: 988/1000 Discriminator Loss: 1.2340 Generator Loss: 0.8023\n",
            "Epoch: 989/1000 Discriminator Loss: 1.2938 Generator Loss: 1.0132\n",
            "Epoch: 990/1000 Discriminator Loss: 1.2395 Generator Loss: 0.8402\n",
            "Epoch: 991/1000 Discriminator Loss: 1.6056 Generator Loss: 0.7771\n",
            "Epoch: 992/1000 Discriminator Loss: 1.2949 Generator Loss: 0.9563\n",
            "Epoch: 993/1000 Discriminator Loss: 1.2915 Generator Loss: 1.0560\n",
            "Epoch: 994/1000 Discriminator Loss: 1.4137 Generator Loss: 0.9089\n",
            "Epoch: 995/1000 Discriminator Loss: 1.4846 Generator Loss: 0.8361\n",
            "Epoch: 996/1000 Discriminator Loss: 1.3778 Generator Loss: 0.9604\n",
            "Epoch: 997/1000 Discriminator Loss: 1.1303 Generator Loss: 1.0035\n",
            "Epoch: 998/1000 Discriminator Loss: 1.2421 Generator Loss: 1.0110\n",
            "Epoch: 999/1000 Discriminator Loss: 1.2305 Generator Loss: 1.2238\n",
            "Epoch: 1000/1000 Discriminator Loss: 1.3347 Generator Loss: 0.9345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L3Um_sTen3X9",
        "colab_type": "code",
        "outputId": "a7c5c43c-a1a2-414a-9c82-0c18e589b2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "losses = np.array(losses)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(losses.T[0], label='Discriminator')\n",
        "plt.plot(losses.T[1], label='Generator')\n",
        "plt.title(\"Training Losses\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCQTXvU+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MobGMRbCosJf",
        "colab_type": "code",
        "outputId": "32c544df-cee7-4e2f-b7ed-b8b57e7c8f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7925
        }
      },
      "cell_type": "code",
      "source": [
        "latent_samples = make_latent_samples(20, sample_size)\n",
        "generated_recipes = generator.predict(latent_samples)\n",
        "\n",
        "for i in range(20):\n",
        "    recipe = deprocess(generated_recipes[i])\n",
        "    original_recipe = full_decode_to_original(recipe, flat_ingredients, flat_steps)\n",
        "    print(json.dumps(original_recipe, indent=2))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ingredients\": [\n",
            "    \"McCormick\\u00ae Ginger, Ground, divided\",\n",
            "    \"Thai-style peanut sauce\",\n",
            "    \"honeydew melon, halved and seeded\",\n",
            "    \"bag frozen bell pepper strips\",\n",
            "    \"green onions, thinly sliced (plus extra for garnish)\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"ears fresh corn, kernels cut off\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Sprinkle cheese over mayonnaise, then top with bacon bits, if using\",\n",
            "    \"Mix together the beef broth and tomato paste and pour into the slow cooker along with the beer\",\n",
            "    \"Combine lime zest, lime juice, sugar and water\",\n",
            "    \"Cool cake on a rack, and frost with a lemon butter icing\",\n",
            "    \"Cook over moderate heat, covered, until the vegetables start to soften, 5 to 10 minutes\",\n",
            "    \"Stir in the tomato paste and then the tomatoes and cayenne\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"Pepperidge Farm\\u00ae Cinnamon Swirl Bread , cut into cubes\",\n",
            "    \"blueberries, halved crosswise\",\n",
            "    \"fully cooked kielbasa, cubed\",\n",
            "    \"can frozen juice concentrate - any flavor except citrus, thawed\",\n",
            "    \"thin slices whole-grain rye bread, toasted\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"sweet Italian sausage links, cut into 1/2-inch pieces\",\n",
            "    \"finely ground walnuts\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Heat oven to 350 degrees F (325 degrees F for dark pan)\",\n",
            "    \"Cover and let rise in a warm place for 30 minutes or until doubled\",\n",
            "    \"In a large saucepan, combine the sugar, red-hots, cloves, orange juice, lemon juice and 4 cups water\",\n",
            "    \"In a mixing bowl, beat milk, sherbet and ice cream until frothy\",\n",
            "    \"Shape the dough into a loaf and place into the pan\",\n",
            "    \"Stir in red bell pepper mixture\",\n",
            "    \"Serve pork and broccoli over ramen noodles\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"unblanched almonds, sliced\",\n",
            "    \"cooked penne pasta\",\n",
            "    \"ear fresh corn in the husk\",\n",
            "    \"sliced bacon, cut crosswise into 1/2-inch strips\",\n",
            "    \"eggs, Isaiah 10:14\",\n",
            "    \"fluid ounces Dubonnet rouge\",\n",
            "    \"small leeks, white part only, julienned\",\n",
            "    \"pepperonchinis, sliced thinly\",\n",
            "    \"sprigs fresh cilantro, minced (optional)\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"Italian sausage links, halved lengthwise\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Toss olives, oil, oregano, basil, garlic and pepper in a medium bowl\",\n",
            "    \"Cream together 1 cup softened butter and sugar\",\n",
            "    \"Simmer 3 more minutes before adjusting salt and black pepper\",\n",
            "    \"Place scoops of the frozen mixture into serving glasses, and fill the rest of the glass with lemon-lime soda\",\n",
            "    \"Brush over entire loaf; sprinkle with remaining almonds\",\n",
            "    \"Drizzle ice cream topping over cooled cookies\",\n",
            "    \"Whisk oil, milk, egg, and almond extract together in a small bowl\",\n",
            "    \"Line a loaf pan with parchment paper, leaving an overhang on both sides\",\n",
            "    \"Reduce heat to medium, and stir in the onion and garlic\",\n",
            "    \"Press mixture into an ungreased 8-in\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"bone-in leg of lamb, or more to taste\",\n",
            "    \"medium DOLE Strawberries\",\n",
            "    \"golden or dark raisins\",\n",
            "    \"banana leaves, or as needed\",\n",
            "    \"fresh grated ginger\",\n",
            "    \"sliced Havarti cheese with dill\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Drain onion\",\n",
            "    \"Let stand on the cookie sheet for 1 minute before removing to wire racks to cool completely\",\n",
            "    \"In a large bowl, combine the coleslaw, green onions, toasted ramen noodles and cashews\",\n",
            "    \"Pour cheese mixture over crust\",\n",
            "    \"Bake 8 to 10 minutes, stirring once, or until crisp\",\n",
            "    \"Prepare chicken\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"teriyaki marinade sauce\",\n",
            "    \"large firm bananas, cut into 1/2-inch slices\",\n",
            "    \"fresh lemon juice, or as needed\",\n",
            "    \"sliced snow peas\",\n",
            "    \"milled flax seeds\",\n",
            "    \"bite-sized garlic-flavored bagel chips\",\n",
            "    \"cans Mexican-style corn (such as Green Giant\\u00ae), drained\",\n",
            "    \"raw lobster tail, quartered\",\n",
            "    \"dried dates, halved and pitted\",\n",
            "    \"can premium canned chicken, minced\",\n",
            "    \"Swanson\\u00ae Seafood Stock\",\n",
            "    \"dried pinto beans, washed\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"shortening (not butter, margarine, spread or oil)\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Curve top of rope down to look like the handle of a candy cane\",\n",
            "    \"Season with soy sauce or lime juice, as desired\",\n",
            "    \"Drain fettuccine; toss with ham mixture\",\n",
            "    \"Pour in vegetable broth; bring to a boil\",\n",
            "    \"Combine dates and walnuts; stir into batter (the batter will be stiff)\",\n",
            "    \"Spoon apple filling into pie shell\",\n",
            "    \"Heat olive oil in a 10-inch nonstick skillet with an ovenproof handle over medium-high heat\",\n",
            "    \"Season with sea salt and pepper and serve with lime wedges\",\n",
            "    \"Marinate the pork in juice of one lime while you prepare a medium-hot fire (5 to 8 minutes)\",\n",
            "    \"Place a cast iron skillet in the preheated oven for 15 minutes\",\n",
            "    \"Place saucepan over medium heat; cook and stir mixture is the consistency of pudding, about 10 minutes\",\n",
            "    \"Rub the garlic and pepper into the meat\",\n",
            "    \"For added appeal, serve over crushed ice\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"can pineapple rings\",\n",
            "    \"frozen leaf spinach, thawed\",\n",
            "    \"can solid white tuna packed in water, drained\",\n",
            "    \"green onion, chopped, divided\",\n",
            "    \"sweet potatoes, sliced lengthwise into quarters\",\n",
            "    \"fresh Shanghai-style or udon noodles (about 1/4 inch thick), rinsed and drained\",\n",
            "    \"leeks (white and pale green parts only), thinly sliced\",\n",
            "    \"can Pillsbury\\u00ae Refrigerated Crescent Dinner Rolls\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"garlic salt to taste\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Combine hot water and saffron in a small bowl; let sit until water turns yellow\",\n",
            "    \"Press half the oat mixture into the prepared baking dish\",\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"In a small bowl, combine dressing mix and sour cream; mix well\",\n",
            "    \"Place oven rack in it's highest position\",\n",
            "    \"Finely grind cumin seeds in an electric coffee/spice grinder or with a mortar and pestle\",\n",
            "    \"Bring the water to a boil in a saucepan, reduce heat to medium-low, and stir in the savory, parsley, red pepper flakes, and chicken bouillon granules until the granules dissolve\",\n",
            "    \"Mix the cream cheese, Cheddar cheese, green chilies, chili powder, enchilada sauce, button mushrooms, and heavy cream in a large bowl\",\n",
            "    \"Add the lentils, chili powder, cumin and oregano; cook and stir for 1 minute\",\n",
            "    \"Remove from the batter and allow the excess to drip off, back into the bowl\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"large Granny Smith apples, julienned\",\n",
            "    \"pieces NESTLE\\u00ae BUTTERFINGER\\u00ae Bites Candy, chopped, or more if desired\",\n",
            "    \"salmon fillets, skin removed, if desired\",\n",
            "    \"slices oat-nut bread\",\n",
            "    \"yellow chili pepper\",\n",
            "    \"capers in salt, well rinsed and minced\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Store, well covered, in a greased bowl in the refrigerator\",\n",
            "    \"Stir and heat until mixture begins to thicken\",\n",
            "    \"Bake for 50 to 60 minutes or until toothpick comes out clean\",\n",
            "    \"Repeat with the remaining rhubarb, strawberries and cream\",\n",
            "    \"Bake at 350 degrees F (175 degrees C) for 15 to 20 minutes or until wrapper is crisp\",\n",
            "    \"Pour the oat bran in a blender and process until the flakes become powder\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"thin-sliced cooked corned beef\",\n",
            "    \"small banana, sliced\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"slices sharp Cheddar cheese, cut in half\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Freeze in ice-cream maker\",\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"In a large bowl, mix the soup, milk, water, chicken, rice, green beans, Cheddar cheese, onion, and garlic\",\n",
            "    \"Place in preheated oven\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"reduced fat pork sausage\",\n",
            "    \"miniature semisweet chocolate pieces\",\n",
            "    \"can diced green chilies, drained\",\n",
            "    \"can pear halves, well drained\",\n",
            "    \"pine nuts, finely chopped\",\n",
            "    \"roasted red peppers, drained and chopped\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"phyllo sheets, thawed if frozen\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"In a large nonstick skillet, cook the mushrooms over medium-high heat, stirring often, for 5 minutes, or until dry; transfer the mushrooms to a plate\",\n",
            "    \"Cook, stirring frequently with a whisk, until thickened and smooth, about 3 minutes; cool\",\n",
            "    \"Cut a large pocket into the pork chops using a sharp, thin bladed knife\",\n",
            "    \"Cook, without stirring, until eggs begin to set on bottom\",\n",
            "    \"Slice hot dogs in half lengthwise; place two halves on each bun\",\n",
            "    \"Cover dough with cheesecloth; let rest, about 5 minutes\",\n",
            "    \"Meanwhile, in small bowl, combine pineapple, onion, pepper, juice from 1/2 the lime and 1/4 cup cilantro\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"plain fat-free Greek yogurt, or more as needed\",\n",
            "    \"shallot, sliced thin\",\n",
            "    \"maple flavor syrup\",\n",
            "    \"red pepper, washed, seeded and sliced\",\n",
            "    \"whole dried chile peppers, cut in half\",\n",
            "    \"Safeway SELECT Southwest Salsa, medium or mild, or to taste\",\n",
            "    \"ripe pear, cored and coarsely chopped\",\n",
            "    \"dried cranberries, roughly chopped\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"romaine lettuce hearts, cut into bite-size chunks\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Refrigerate at least 30 minutes\",\n",
            "    \"Boil 5 minutes\",\n",
            "    \"Add tortillas strips; simmer for 5 minutes longer\",\n",
            "    \"Fold the top and bottom corners in toward each other and roll it up like a little egg roll\",\n",
            "    \"Combine the remaining ingredients; pour over beans and toss to coat evenly\",\n",
            "    \"In a bowl, combine the buttermilk and cereal; let stand for 10 minutes\",\n",
            "    \"Combine the eggs and sugar in a large heatproof bowl and set on top of a pan of simmering water\",\n",
            "    \"Add the mussels, and steam over high heat until they are all open, 5 to 10 minutes\",\n",
            "    \"Serve topped with a dollop of ricotta cheese\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"frozen peas\",\n",
            "    \"scallions, cut into 3-inch pieces and sliced lengthwise into thin strips\",\n",
            "    \"strips bacon, diced\",\n",
            "    \"slices Genoa salami, chopped\",\n",
            "    \"large avocados - peeled, pitted, and cut into bite-sized pieces\",\n",
            "    \"thyme, leaf\",\n",
            "    \"wedge lime for garnish\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"fluid ounce lime juice\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Remove with a slotted spoon and reserve\",\n",
            "    \"Fill a glass with ice; pour cocktail over ice\",\n",
            "    \"Allow to cool in pans for about 10 minutes before removing to finish cooling on racks\",\n",
            "    \"Arrange lemon slices in two layers in the center of the foil\",\n",
            "    \"Stir desired food color, one drop at a time, into each until desired color\",\n",
            "    \"Return the salmon to the skillet and allow to simmer in the sauce until the fish flakes easily with a fork, about 10 minutes\",\n",
            "    \"Transfer mixture to serving bowls and top with spring onions\",\n",
            "    \"Beat eggs until frothy, add sugars and vanilla\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"skinless, boneless salmon fillets\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Add mint and berries to dressing; toss gently to coat\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"can RED GOLD\\u00ae PETITE DICED TOMATOES or REDPACK\\u00ae PETITE DICED TOMATOES, drained\",\n",
            "    \"bunch green onions, chopped, or to taste\",\n",
            "    \"Roma tomatoes, sliced 1/4-inch thick\",\n",
            "    \"slices lemon, for garnish (optional)\",\n",
            "    \"frozen peas, defrosted\",\n",
            "    \"semolina\",\n",
            "    \"shaved Parmesan cheese\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Place grated cucumber in a fine mesh strainer; allow to drain 1 to 2 hours\",\n",
            "    \"Pour chicken and Alfredo sauce mixture over noodle layer and spread evenly\",\n",
            "    \"Combine flour, baking powder and baking soda; add to the creamed mixture and mix well\",\n",
            "    \"Combine flour, baking powder, baking soda and salt; add to creamed mixture and beat until combined\",\n",
            "    \"In a medium baking pan, toss together the zucchini, potatoes, red bell pepper, garlic, bread crumbs, and olive oil\",\n",
            "    \"Stir in the tomatoes, olives, wine, and parsley\",\n",
            "    \"Remove from the heat, and stir in the cream of mushroom soup\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"apple, cut into 1/4-inch pieces\",\n",
            "    \"cans whole peeled San Marzano tomatoes\",\n",
            "    \"PLANTERS Cocktail Peanuts, chopped\",\n",
            "    \"strawberries, rinsed\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"medium tomato, seeded and diced\",\n",
            "    \"Archer Farms\\u00ae cumin\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Cover container tightly and freeze slush overnight\",\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Garnish with whipped cream, 3 coffee beans and 1 vanilla bean\",\n",
            "    \"Slice peppers lengthwise, remove seeds and core; fill with cheese\",\n",
            "    \"Meanwhile, brush large baking sheet with oil\",\n",
            "    \"Add carrots; mix until well blended\",\n",
            "    \"Drizzle 4 teaspoons maple syrup over strawberries in a bowl; stir to coat\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"fresh or frozen cranberries, thawed and coarsely chopped\",\n",
            "    \"fully baked pizza crust\",\n",
            "    \"precooked (instant) dried white rice\",\n",
            "    \"eggplant, cut into 1 1/2-inch cubes\",\n",
            "    \"smoked sausage, cut into half moons\",\n",
            "    \"McCormick\\u00ae Ground Thyme\",\n",
            "    \"jalapeno pepper, diced (optional)\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"refrigerated cooked Italian-style chicken breast strips, chopped\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Stir in the flour mixture just until all ingredients are moistened\",\n",
            "    \"Flip and brush with warm marinade\",\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Combine topping ingredients; sprinkle over sweet potato mixture\",\n",
            "    \"Stir and heat until mixture begins to thicken\",\n",
            "    \"Cook onions over medium heat for 10 minutes, or until golden brown\",\n",
            "    \"In a large skillet, heat the olive oil over medium-high heat\",\n",
            "    \"In 10-inch skillet, cook beef over medium heat 8 to 10 minutes, stirring occasionally, until thoroughly cooked; drain\",\n",
            "    \"Add vanilla and salt to taste\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"arugula (optional)\",\n",
            "    \"jalapeno liquid (from jar)\",\n",
            "    \"frozen strawberries or raspberries\",\n",
            "    \"rib celery, sliced\",\n",
            "    \"raw cashew nuts\",\n",
            "    \"large red bell peppers - seeded, cored, and chopped\",\n",
            "    \"coarse-grain brown mustard\",\n",
            "    \"crushed herb seasoned stuffing\",\n",
            "    \"box uncooked plain couscous\",\n",
            "    \"Chinese cooking wine (Shaoxing wine)\",\n",
            "    \"coarsely chopped parsley, or to taste\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"olive oil, plus more if needed\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Add tomatoes; simmer 8 min\",\n",
            "    \"Top with the whipped topping and chopped candy canes just before serving\",\n",
            "    \"Add bell pepper and onion; cook, stirring often, until beginning to soften, about 4 minutes\",\n",
            "    \"Serve garnished with the sour cream and a sprinkle of fresh dill\",\n",
            "    \"Beat in orange marmalade and confectioners' sugar\",\n",
            "    \"Spread between cake layers\",\n",
            "    \"Place coated chicken into skillet with onion mixture\",\n",
            "    \"Whisk together the honey, ground chipotle pepper, Dijon mustard, olive oil, tea, apple cider vinegar, and salt until the mixture is smooth and the salt has dissolved\",\n",
            "    \"Pour in wine; simmer until reduced by half, about 3 minutes\",\n",
            "    \"In a small saucepan, combine JIF(R), honey and cinnamon; heat through\",\n",
            "    \"Replace cover and cook until chicken is no longer pink at the bone and juices run clear, about 5 minutes more\",\n",
            "    \"Mix in the poultry seasoning, salt, pepper, eggs and milk\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"McCormick\\u00ae Coarse Grind Black Pepper, divided\",\n",
            "    \"soybean oil (vegetable oil)\",\n",
            "    \"whole baby carrots, green tops removed, cut into 2-inch pieces\",\n",
            "    \"pint fresh strawberries, washed\",\n",
            "    \"medium red or yellow bell pepper, cut into strips\",\n",
            "    \"bottles white rum\",\n",
            "    \"tahini salad dressing\",\n",
            "    \"bottle white wine vinegar\",\n",
            "    \"tempeh, crumbled\",\n",
            "    \"bag mixed salad greens, such as Mediterranean or European mix\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"vanilla low-fat yogurt (optional)\",\n",
            "    \"Gruyere cheese or Swiss cheese\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Pour on rum, vermouth and banana liqueur\",\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"In a bowl, mix together the honey, chili powder, cumin, cayenne pepper, salt, and garlic powder\",\n",
            "    \"Combine first six ingredients in a small bowl\",\n",
            "    \"Press puff pastry sheet into the bottom and up the sides of a shallow casserole dish or 8-inch pie plate\",\n",
            "    \"Allow to cool completely before storing in airtight canister or resealable plastic bag\",\n",
            "    \"In a lightly greased 9x13 inch baking dish layer the casserole as follows: First, all of the broccoli, then 1/3 of the cheese, then all of the chicken, another 1/3 of the cheese, all of the white wine/soup mixture and, finally, top with the bread crumbs and the last 1/3 of the cheese\",\n",
            "    \"Sprinkle cake with streusel topping\",\n",
            "    \"Pour amaretto into a highball glass\",\n",
            "    \"Roll kale leaves into tight tubes and cut crosswise into 1/4-inch strips\",\n",
            "    \"Shake container occasionally to cover meat\",\n",
            "    \"In a microwave-safe bowl, combine the cheese and milk\",\n",
            "    \"Add asparagus to skillet\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"coarsely chopped assorted NESTLE\\u00ae candy such as BABY RUTH\\u00ae, GOOBERS\\u00ae, BUTTERFINGER\\u00ae, NESTLE\\u00ae CRUNCH\\u00ae, NESTLE\\u00ae RAISINETS\\u00ae, or BUNCHA CRUNCH\\u00ae\",\n",
            "    \"center-cut pork chops\",\n",
            "    \"zucchini, cut into 1/2 inch dice\",\n",
            "    \"large DOLE Banana, sliced\",\n",
            "    \"thinly sliced lettuce\",\n",
            "    \"can Market Pantry\\u2122 cream-style sweet corn\",\n",
            "    \"sliced fresh fruit\",\n",
            "    \"VH\\u00ae Sweet Thai Chili Sauce\",\n",
            "    \"herbes de Provence or dried Italian seasoning, crushed\",\n",
            "    \"bottle champagne, or more to taste\",\n",
            "    \"Yukon gold potato, very thinly sliced\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"bag frozen pitted cherries\",\n",
            "    \"grated lime peel\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Split dinner rolls in half and set top half aside\",\n",
            "    \"Reduce heat to medium-low, cover, and simmer until the rice is tender but not mushy, 30 to 45 minutes\",\n",
            "    \"Heat a large skillet coated with cooking spray over medium-high heat\",\n",
            "    \"Stir dry milk, honey, and vanilla together in a bowl; beat in eggs\",\n",
            "    \"Whisk half-and-half, horseradish mustard, lemon juice, and thyme into onion mixture until mustard sauce is smooth and heated through, about 5 minutes\",\n",
            "    \"Bake at 400 degrees F for 20 minutes or until hot\",\n",
            "    \"Place one shrimp inside each jalapeno half, and wrap with a slice of bacon\",\n",
            "    \"Combine soup, milk and parsley; pour over chicken\",\n",
            "    \"Reduce heat, cover and simmer 1 hour, or until tender\",\n",
            "    \"Lightly coat the bottom of a 13x9-inch baking dish with cooking spray\",\n",
            "    \"Bake for 25 minutes or until cheese is melted and bubbly\",\n",
            "    \"Prepare medium-hot fire with charcoal or preheat gas to medium high\",\n",
            "    \"Trim straws to just barely protrude from the top of the cups\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"bar semisweet chocolate, chopped\",\n",
            "    \"dried mushrooms (such as porcini)\",\n",
            "    \"turkey ham, diced\",\n",
            "    \"jar buttermilk ranch dressing\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Remove top sheet of parchment and immediately cut brittle into pieces with a heavy knife or pizza wheel\",\n",
            "    \"Lay banana slices on bread (tip: DEJ prefers three slices), topping with the other slice of bread\",\n",
            "    \"Stir in spinach and cover; cook until spinach starts to wilt, about 5 minutes\",\n",
            "    \"Cook cakes in oil for about 5 minutes per side, or until golden brown and cooked through\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"ingredients\": [\n",
            "    \"sliced Margarita\\u00ae Mortadella or Hot or Sweet Capicola\",\n",
            "    \"grams M&M;'S\\u00ae Milk Chocolate, Peanut or Mint Holiday Mix Chocolate Candies\",\n",
            "    \"RICE-A-RONI\\u00ae Red Beans & Rice\",\n",
            "    \"chopped O Organics Tarragon\",\n",
            "    \"dried Great Northern beans\",\n",
            "    \"Market Pantry\\u2122 brown sugar\",\n",
            "    \"sliced or cut up fresh fruit, such as strawberries, peaches, nectarines and/or kiwi fruit\",\n",
            "    \"chopped mustard greens (leaves only)\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"Spoon fruit over crepes\",\n",
            "    \"Place on a wire rack until chocolate has hardened\",\n",
            "    \"Gently place the cucumber slices into the hot oil and cook until golden brown on both sides, about 3 to 4 minutes\",\n",
            "    \"Beat milk and vanilla pudding mix together until smooth\",\n",
            "    \"Brush with 1 tablespoon butter, drizzle lemon juice over the top, and dust with confectioners' sugar\",\n",
            "    \"Stir cookie dough until well-mixed\",\n",
            "    \"Arrange one skewer on to each romaine leaf\",\n",
            "    \"Cook, stirring constantly until the custard has thickened and will stick to the back of a spoon, about 10 minutes\"\n",
            "  ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
